
该系列翻译自《Understanding Diffusion Models: A Unified Perspective》Calvin Luo, Google Research, Brain Team

## 1.1 生成模型
一个样本 $x$ 从我们感兴趣的分布中观测到，**生成模型**的目的就是学习建模这个真实的数据分布 $p(x)$ 。一旦学习到 $p(x)$ ，我们就可以随意地从该分布中获取生成我们感兴趣的其他样本。此外，在一些公式下，我们也可以使用这些学习到的模型来评估“观测”或“抽样”到的其他数据的质量。
在目前的文献中有几个众所周知的方向，我们简要回顾一下：
1. 生成对抗性网络（GANs），对复杂分布的抽样过程进行建模，并以对抗性的方式进行学习。
2. 还有一种基于“似然”的生成模型，该模型试图学习一个使观察数据样本可能性最大化的模型。这包括自回归模型、规范化流和变分自动编码器（VAEs）。
3. 最后一种方案是基于”能量“的建模，这种分布被学习成一个任意的能量函数，然后被归一化。基于分数（Score-based）的生成模型就很像这种模式；但他不是学习能量函数本身，而是学习能量模型的分数，从而进行神经网络建模。
在本文中，我们探索和回顾扩散模型，正如我们将证明的那样，它有基于”似然“的解释，也有基于”分数“的解释 。我们会详细展示这些模型背后的数学原理， 目的是让任何人都可以跟踪和理解什么是扩散模型以及它们是如何工作的。

## 1.2 背景： ELBO、VAE和层次化VAE
对于许多模式，我们可以认为我们观察到的数据是由一个看不见却有联系的潜在变量（latent variable）表示或生成的，我们可以用随机变量 $z$ 来表示它。表达这一观点的最好的例子就是柏拉图的“洞穴寓言”。（如下图，来自于维基百科）在寓言中，一群人一生都被锁在一个洞穴里，只能看到投射在他们前面一堵墙上的二维阴影。（如图左边）这些阴影是由洞穴人看不见的三维物体经过火把前产生的。 对这些洞穴人来说，他们所观察到的一切实际上都是由他们永远无法看到的高维抽象概念所决定的。

![洞穴寓言](images/洞穴寓言.jpeg)

类似地，我们在现实世界中遇到的对象也可以作为一些高级表示的函数生成；例如，这种表示可能封装抽象属性 , 如颜色、大小、形状等。然后，我们观察到的可以被解释为这些抽象概念的三维投影或实例化，就像洞穴人们 观察到的实际上是三维物体的二维投影一样。虽然洞穴里的人永远看不到（甚至完全理解）隐藏的物体，但他们 仍然可以对它们进行推理和推断； 以类似的方式，我们可以近似地描述我们观察到的数据的潜在表征。

柏拉图的寓言说明了通过观察决定潜在变量建模，但是这个类比必须要说明：在生成建模中，我们通常寻求学习低维的潜在变量，而不是高维的潜在变量。这是因为学习到比观察数据维度更高维度的表示，在没有强先验的情况是徒劳的努力。（译者言，类似熵增原理：“在孤立系统中，熵（混乱程度）不会减少，总是增大或者不变”。在没有其他信息的情况下，低维数据变高维数据是行不通的。）另一方面，学习低维潜在变量也可以被视为一中在语义上获得数据特征的压缩。


### 1.2.1 证据下界（Evidence Lower Bound，ELBO）

在数学上，我们可以假设潜在的隐变量 $z$ （后面我们会用学术上更常用的“隐变量”一词，就是前面说的“潜在变量”）和我们观察到的数据 $x$ 是由一个联合分布$p(x,z)$ 建模的。回想一下，基于“似然”的生成建模过程，就是学习一个最大化所有观察 $x$ 的概率 $p(x)$ 的模型。我们有两种方法操作：
我们可以对边缘化隐变量 $z$ 积分：
$$p(x)= \int p(x,z)dz \tag{1}$$

或者，我们也可以求助于概率的链式法则：
$$p(x)=\frac {p(x,z)}{p(z|x)} \tag{2}$$
直接通过计算或最大化似然来获取 $p(x)$ 是困难的，因为它要么涉及到方程（1）中的所有隐变量z的计算，如果是复杂模型会非常棘手的；它要么涉及到方程（2）中需要获取隐变量真实值的解码器 $p(z|x)$ 计算。
但是如果我们利用这两个方程，就可以推导出 $p(x)$ 的证据下界（ELBO）。“最大化ELBO”即为优化目标函数的**代理目标函数**。当然，最完美的情况就是ELBO完全等价于目标函数。这里，我们使用的ELBO形式为：
$$\mathbb{E}_{q_\phi(z|x)}[\log\frac{p(x,z)}{q_\phi(z|x)}] \tag{3}$$
它与 $p(x)$ 的关系是 
$$\log p(x) \geq \mathbb{E}_{q_\phi(z|x)}[\log\frac{p(x,z)}{q_\phi(z|x)}] \tag{4}$$
$q_\phi (z|x)$ 在这里是一个针对参数 $\phi$ 优化的灵活分布。直观地说，它可被认为是一个用 $\phi$ 参数模型来估计给定观测 $x$ 的隐变量的真实分布。换句话说，它寻求近似真实的后验 $p(z|x)$ 。我们通过调节参数 $\phi$ 来探索“变分自编码器”时，可以控制增加下界以最大化ELBO。现在，让我们试着深入研究一下为什么ELBO是一个我们想要最大化的目标。
让我们从用方程（1）推导ELBO：
$$
 \begin{align} 
\log p(x)& = \log \int p(x,z)dz \tag{5}\\ 
&= \log \int \frac {p(x,z)q_\phi(z|x)}{q_\phi(z|x)}dz \tag{6}\\
&= \log \mathbb{E}_{q_\phi(z|x)}[\frac{p(x,z)}{q_\phi(z|x)}]  \tag{7}\\
&\geq \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)}{q_\phi(z|x)}}] \tag{8}
 \end{align}
$$
***
译者言：公式（7）中原文说是使用期望的定义如下公式，其中 $f(x)$ 称为X的概率密度函数。
$$E(X) = \int_{-\infty}^{+\infty} xf(x)dx$$
直接套公式有错误。的确，原文在此处写得不妥当，它实际使用的是如下定理：
若随机变量 $Y$ 符合函数 $Y=g(x)$ ，且 $\int_{-\infty}^{+\infty} g(x)f(x)dx$ 绝对收敛，则有
$$E(Y)=E(g(X)) = \int_{-\infty}^{+\infty} g(x)f(x)dx \tag{定理1}$$我们的大学概率论书籍对此证明一笔带过，因为证明过程特别复杂。请记住这个定理，后面还会使用。请注意，其中 $f(x)$ 要求是概率密度，$g(x)$ 可以不是。

译者言：公式（8）使用的Jensen不等式。Jenson不等式定义：在不等式中，若 $f(x)$ 为区间  $I$  上的下凸函数，则对于任意 $x_i∈I$ ，在满足$\sum_{i=1}^{n} \lambda_i =1$ 的 $\lambda_i>0(i=1,2,⋯,n)$ 时，下公式成立：
$$ f(\sum_{i=1}^n \lambda_i x_i) \leqslant \sum_{i=1}^n \lambda_i f(x_i)$$
本文中应用的是连续性公式，道理相似。
***
我们通过应用Jensen不等式直接得到了我们的下界。然而，这个推导没有提供关于问题本质的实际信息；特别地，利用 Jensen 不等式得出的结论看起来并没有解释为什么 ELBO 确实是证据（真实分布）的下界。退一步讲，即使知道 ELBO 真的是证据下界并不能说明我们为什么想将其最大化作为目标。为了更好地理解证据（真实分布）与ELBO之间的关系，我们再进行另一次推导：
$$
\begin{align} 
\log p(x)& = \log p(x) \int q_\phi(z|x)dz \tag{9}\\ 
&= \int q_\phi(z|x)(\log p(x))dz \tag{10}\\
&= \mathbb{E}_{q_\phi(z|x)}[\log{p(x)}]  \tag{11}\\
&= \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)}{p(z|x)}}] \tag{12}\\
&= \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)q_\phi(z|x)}{p(z|x)q_\phi(z|x)}}] \tag{13} \\
&= \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)}{q_\phi(z|x)}}]  + \mathbb{E}_{q_\phi(z|x)}[\log{\frac{q_\phi(z|x)}{p(z|x)}}] \tag{14}\\
&= \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)}{q_\phi(z|x)}}]  + D_{KL}(q_\phi(z|x)||p(z|x)) \tag{15}\\
&\geq \mathbb{E}_{q_\phi(z|x)}[\log{\frac{p(x,z)}{q_\phi(z|x)}}]  \tag{16}\\
\end{align}
$$
***
译者言：原文说，从公式（10）到（11）使用的是期望概念，但我们在公式（7）的推理问题已经提到，这其实是使用定理1，其中 $q_\phi(z|x)$ 是概率密度函数，对 $z$ 积分等于1。
公式（14）到公式（15），使用的KL散度公式，KL散度必不小于0，其定义为：
$$KL(P||Q)=\int p(x) \log\frac{P(x)}{Q(x)} dx$$
***
从这个推导中，我们从公式（15）清楚地观察到，证据（真实分布）等于ELBO加上近似后验 $q_\phi(z|x)$ 和真正后验 $p(z|x)$ 之间的KL散度。事实上，正是这个KL散度项被第一次推导的公式（8）中的Jensen不等式神奇地消除了。理解这一情形不仅是理解ELBO和证据（真实分布）之间关系的关键，也是理解为什么优化ELBO就是的优化目标函数的原因。

![](images/1.2.1-1.png)

*图1. 变分自动编码器的图形化表示。编码器 $q(z|x)$ 定义了观测值 $x$ 的隐变量 $z$ 上的分布，而 $p(x|z)$ 将隐变量解码为观测值。*

首先，我们现在知道为什么ELBO确实是一个下界：证据（真实分布）和ELBO之间的差异是中间夹扎着一个严格的非负的KL项，因此ELBO的值永远不能超过证据（真实分布）。
其次，我们探讨为什么我们寻求最大化ELBO。在引入了我们想要建模的隐变量z之后，我们的目标是学习描述观察到的数据的潜在结构。换句话说，我们想要优化我们的变分近视后验  $q_\phi(z|x)$ 以精确匹配真实后验 $p(z|x)$。这种匹配是通过最小化它们的KL散度（理想情况下为零）来实现的。不幸的是，直接最小化这个KL散度项是很困难的，因为我们无法获得 $p(z|x)$ 的gound- truth分布。然而根据公式（15）的左侧，数据的似然项（真实分布 $\log p(x)$ 项）总是一个相当于 $\phi$ 的常数，因为它从联合分布 $p(x,z)$ 中累计计算出所有隐变量 z，不依赖于任何 $\phi$ 。由于ELBO和KL散度项之和为一个常数，因此关于ELBO项的任何最大化都必然会使KL散度项的相等最小化 。因此，“最大化ELBO”可以作为完美建模真实隐后验分布的代理；我们优化的ELBO越多，我们的近似后验就越接近真实后验。此外，一旦训练，ELBO也可以被用来估计观察数据的似然或生成数据的概率，因为它被用来学习逼近建模证据项 $\log p(x)$。

### 1.2.2 变分自编码器 （Variational Autoencoders， VAE）

**使用变分自动编码器（VAE）的默认公式，我们可以用来最大化ELBO项。** （译者言：下面也是VAE的推理过程）我们从一系列由 $\phi$ 参数组成的潜在分布中优化最佳的 $q_\phi(z|x)$，这种方案叫“变分variational”。输入数据会经过一个瓶颈表示后再训练预测自己，这种自编码结构被称为“自编码器autoencoders”。为了明确这种联系，让我们进一步分析 ELBO：
$$
\begin{align} 
\mathbb{E}_{q_\phi(z|x)}[\log\frac{p(x,z)}{q_\phi(z|x)}] &= \mathbb{E}_{q_\phi(z|x)}[\log\frac{p_\theta(x|z)p(z)}{q_\phi(z|x)}] \tag{17} \\
&= \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] + \mathbb{E}_{q_\phi(z|x)}[\log\frac{p(z)}{q_\phi(z|x)}] \tag{18} \\
&= \underbrace{\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)]}_{重建项} - \underbrace{D_{KL}(q_\phi(z|x)||p(z))}_{先验匹配项} \tag{19}
\end{align} 
$$
在这里，我们学习了一个可以被视为**编码器**的中间瓶颈分布 $q_\phi(z|x)$ ；它将输入转换为含隐变量的分布。同时，我们学习了一个反向函数 $p_\theta(x|z)$ 作为**解码器**，将给定的隐变量 $z$ 转换为观测值 $x$ 。
方程（19）中的两项都有明确的含义：第一项决定我们在变分分布中使用“编码器-解码器结构”重构分布的可能性，这保证了学习到的分布是利用有效隐变量再生的原始数据；第二项记录了学习到的变分分布与持有先验信息的隐变量相似程度，最小化这项会鼓励编码器实际上学习到一个分布而不是坍缩成一个狄拉克函数。因此，最大化ELBO相当于公式（19）中最大化它的第一项和最小化其第二项。
从VAE定义出发，我们可以了解如何使用参数 $\phi$ 、参数 $\theta$ 联合优化ELBO。VAE的**编码器**通常选择用一个具有对角协方差的多元高斯来建模，先验通常被选择为标准的多元高斯，如下：
$$
\begin{align} 
q_\phi(z|x)&=\mathcal{N}(z; \mu_\phi(x),\sigma^{2}_{\phi}(x)I ) \tag{20} \\
p(z)&= \mathcal{N}(z;0,I) \tag{21}
\end{align} 
$$
我们可以直接计算ELBO的KL散度项（译者言：公式（19）中先验匹配项），还可以用蒙特卡洛估计来近似的重建项（译者言：reconstruction term，公式（19）中重建项）。此时，我们的目标可以重写为：
$$
\arg\max_{\phi,\theta} \mathbb{E}_{q_\phi(z|x）}[\log p_\theta(x|z)]−D_{KL}(q_\phi(z|x)||p(z)) \approx \arg \max_{\phi,\theta} \frac{1}{l}\sum_{l=1}^{L} \log p_\theta(x|z^{(l)})−D_{KL}(q_\phi(z|x)||p(z)) \tag{22}
$$
***
译者言：蒙特卡洛方法的核心思想是利用随机抽样来估计一个不确定的量,这种估计本质上源自大数定理。在期望上我们先考虑公式：
$$
\mathbb{E}_{p(x)}[f(x)]=\int_{-\infty}^{+\infty} f(x)p(x)dx
$$
如要使用蒙特卡洛方法来估计，我们可以遵循以下步骤：
1. 生成随机样本：首先， 根据 $p(x)$ 分布的情况采样一系列随机点 $X_1,…,X_n$ 。
2. 计算样本的函数值：接下来，对于每一个随机采样 $X_i$​ ，计算 $f(X_i)$ 的值。
3. 期望估计：计算 $Q_n=\frac{1}{n}\sum_{i=1}^nf(X_i)$ 的值即为期望 $\mathbb{E}_{p(x)}[f(x)]$ 的近似值
回到公式（22），根据公式（9）我们可以推断是对 $z$ 进行采样。
📢📢📢📢📢📢
注意：原文公式（22）中没有乘以 $\frac{1}{l}$ ，这里我加了。虽然译者对原论文公式更改不对，但原公式的确有问题。
📢📢📢📢📢📢
***
在默认设置中，我们从数据集的每个观察值$x$ 中，使用 $q_\phi(z|x)$ 对 隐变量 $\{z^{(l)}\}_{l=1}^{L}$ 采样 。然而，这种默认出现了一个问题：在我们损失计算时，对于每个隐变量 $z^{(l)}$ 是根据一个随机抽样过程产生的，它通常是不可微的。幸运的是，当 $q_\phi(z|x)$ 被设计用来模拟某些特定分布（包括多元高斯分布）时，这些可以通过**重参数化**技巧来解决。**重参数化**技巧将一个随机变量重写为一个噪声变量的确定性函数，这将允许通过梯度下降的方法来优化非随机项。例如，来自正态分布 $x\in \mathcal{N}(x;\mu,\sigma^2)$（其中均值和方差分别为 $\mu$ 和 $\sigma^2$ ）可重写为：
$$
x=\mu + \sigma \epsilon, \epsilon \sim \mathcal{N}(\epsilon;0,I)
$$
换句话说，任意高斯分布都可以解释为以 $\epsilon$ 为采样的标准高斯分布为基准，均值从0平移到目标均值 $\mu$ （上式加法），同时根据方差将 $\epsilon$ 调整 $\sigma$ 倍（上式乘法）。因此，我们只需利用“按目标标准差缩放，按目标均值平移”的重参数化技巧，将在任意高斯分布中采样更改为从标准高斯分布中采样。
在VAE中，每个 $z$ 都是由“输入$x$ ”和“辅助噪声变量 $\epsilon$ ”计算得到的。
$$
z = \mu_\phi(x) + \sigma_\phi(x) \odot \epsilon, \epsilon \sim \mathcal{N}(\epsilon;0,I)
$$
其中⊙表示逐元素乘法。使用这种 $z$ 的重参数化方法根据 $\phi$ 计算出梯度以优化 $\mu_\phi$ 和 $\sigma_\phi$ 。因此，VAE利用重新参数化技巧和蒙特卡洛估计来同时优化 $\phi$  和 $\theta$ 下的ELBO。
在训练一个VAE后，可以通过直接从隐空间 $p(z)$ 中采样，然后通过解码器来生成新的数据。当 $z$ 的维数小于输入 $x$ 的维数时，变分自动编码器可能正在学习紧凑且有用的表示法。此外，当学习到语义上有意义的隐空间时，隐向量可以在传递给解码器之前进行编辑， 以更精确地控制生成的数据。
### 1.2.3 分层变分自编码器 （Hierarchical Variational Autoencoders，HVAE）
分层变分自编码器（HVAE）是变分自编码器（VAE）扩展到多个隐变量层级的推广。在这种形式下，一个隐变量可以被解释为由其他更高级、更抽象的隐变量生成。直观地说，洞穴中的人们将三维对象视为生成他们的二维观察结果的隐变量。因此，从柏拉图洞穴居民的角度，他们的观察结果可以被理解为由两层或多层潜在层级影响的模型。

![](images/1.2.3-1.png)
	*图2. 一个具有T层隐空间的马尔可夫层次变分自编码器。生成过程为一个马尔可夫链，其中每个隐变量 $z_t$ 只从前一个隐变量 $z_{t+1}$ 中生成.*

在HVAE 中，通常具有 T 个层级的模型，每层的隐变量都依赖于前面那层所有的隐变量。但是在这项工作中，我们专注于一种特殊情况，称为马尔可夫 HVAE（Markovian Hierarchical Variational Autoencoder，MHVAE）。在 MHVAE 中，生成过程是一个马尔可夫链，也就是说，从上层到下层的每个转换都是马尔可夫过程的，即每个隐变量 $z_t$ 的解码只会依赖于前一层隐变量 $z_{t+1}$ 。直观地理解，这就好像将多个 VAE 层级堆叠在一起，如图2所示；另一个适当的术语来描述它，就是递归 VAE。数学上，我们将 MHVAE 的联合分布和后验表示为：
$$
\begin{align}
p(x, z_{1:T}) &= p (z_T )p_θ(x|z_1) \prod_{t=2}^T p_θ(z_{t−1}|z_t) \tag{23} \\
q_\phi(z_{1:T}|x) &= q_\phi(z_1|x) \prod^T_{t=2} q_\phi(z_t|z_{t−1}) \tag{24}
\end{align}
$$
简简单单带入ELBO，将公式5-8改写为：
$$
 \begin{align} 
\log p(x)& = \log \int p(x,z_{1:T})dz_{1:T} \tag{25}\\ 
&= \log \int \frac {p(x,z_{1:T})q_\phi(z_{1:T}|x)}{q_\phi(z_{1:T}|x)}dz \tag{26}\\
&= \log \mathbb{E}_{q_\phi(z_{1:T}|x)}[\frac{p(x,z_{1:T})}{q_\phi(z_{1:T}|x)}]  \tag{27}\\
&\geq \mathbb{E}_{q_\phi(z_{1:T}|x)}[\log{\frac{p(x,z_{1:T})}{q_\phi(z_{1:T}|x)}}] \tag{28}
 \end{align}
$$
将公式（23）（24）代入（28）可得：
$$
\mathbb{E}_{q_\phi(z_{1:T}|x)}[\log{\frac{p(x,z_{1:T})}{q_\phi(z_{1:T}|x)}}] = \mathbb{E}_{q_\phi(z_{1:T}|x)}[\log{\frac{p (z_T )p_θ(x|z_1) \prod_{t=2}^T p_θ(z_{t−1}|z_t)}{q_\phi(z_1|x) \prod^T_{t=2} q_\phi(z_t|z_{t−1})}}] \tag{29}
$$
当研究变分扩散模型时，这个目标可以进一步分解为多个可解释的组件。我们下面将研究变分扩散模型。
### 1.2.4 变分扩散模型（Variational Diffusion Models，VDM）
变分扩散模型（Variational Diffusion Model，VDM）最简单的理解方式是将其视为一个具有三点约束的马尔可夫变分自编码器（MHVAE）：
- 每层隐变量维度与数据维度完全相等。
- 每层隐编码器的结构不是学习得来的，而是预定义的线性高斯模型。换句话说，它是以前一层输出为中心的高斯分布。
- 隐编码器的高斯参数随时间变化，使得最终时刻 $T$ 的潜在分布是标准高斯分布。

此外，我们明确保持了MHVAE中的层级转换之间的马尔可夫性质。
让我们详细说明这些假设的含义。根据第一条规则约束，我们可以将真实数据样本和隐变量都表示为 $x_t$，其中 $t=0$ 表示真实数据样本，$t∈[1,T]$ 表示具有 $t$ 索引的对应层级的隐变量。VDM的后验与MHVAE的后验相似（如公式（24）），但现在应该重写为：
$$
q(x_{1:T}|x_0) = \prod^T_{t=1}q(x_t|x_{t−1}) \tag{30}
$$

根据第二条规则约束，编码器中每层隐变量的分布都是围绕其前一个层级隐变量的高斯分布。与MHVAE不同，每个时间步长 $t$ 处的编码器结构不会被学习，它被固定为均值和标准差可以事先设置或可学习到的线性高斯模型。这里，我们将高斯编码器参数化为均值$μ_t(x_t)=\sqrt{α_t}x_{t-1}$和方差$Σ_t(x_t)=(1−α_t)I$。(译者言：后面会证明为什么选这个参数。这里可认为是人为设置)其中参数的选择使得隐变量的方差保持在相同的尺度上；换句话说，编码过程是方差保持（variance-preserving，VP）的。
***
译者言：方差保持（variance-preserving，VP）意为，除了在每一步添加噪声，当前画布的尺寸也会得到调整以保持整体的方差。不过，方差爆炸（VE/variance-exploding）方法也有不少拥趸，其中不会调整画布尺寸，所添加的噪声的方差会无限增大。最值得注意的是 Karras et al. (2022) 使用的方法。某些对于 VP 扩散方法成立的结果对 VE 扩散就不一定成立，反之亦然；并且这一点可能不会被明确提及。如果你在读一篇扩散论文，要确保你知道所使用的构建方法，以及论文中是否做了有关于其的假设。
***
请注意，其他高斯参数化方法也是允许的，并且也会引导出类似的推导结果。主要的观点是 $\alpha_t$ 是一个可以随着层级深度 $t$ 变化（可能是可学习的）的系数，以增加灵活性。在数学上，编码器的转换表示为：
$$
q(x_{1:T}|x_0)=\mathcal{N}(x_t;\sqrt{\alpha_t}x_{t-1},(1-\alpha_t)I) \tag{31}
$$
根据第三条规则约束，根据固定或可学习结构进行调整，$\alpha_t$ 随时间变化最终使 $p(x_T)$ 的分布是一个标准高斯分布。然后，我们可以更新MHVAE的联合分布（公式23），将联合分布用于VDM表示为：
$$
\begin{align}
p(x_{0:T})&=p(x_T)\prod_{t=1}^T p_\theta (x_{t-1}|x_t) \tag{32} \\
\text{where,}& \\
p(x_T)&=\mathcal{N}(x_T;0,I) \tag{33}
\end{align}
$$
综合来看，这组假设性约束描述了一种随着时间推移逐渐给图像输入添加高斯噪声，以致最终完全变为纯高斯噪声的过程。该可视化方式过程在图3中展示。

![](images/1.2.4-1.png)
	*图3.  VDM的直观表达。$x_0$ 代表真实观察到的数据，例如真实图片，$x_T$代表纯高斯噪音，$x_t$ 是 $x_0$ 计算的中间噪声版本 。每个 $q(x_t|x_{t-1})$ 被定义为使用前一轮输出状态作为均值的高斯分布。*

值得注意的是，在上图3中，编码器分布 $q(x_t|x_{t−1})$ 不再相1.2.3中由 $\phi$ 参数化，因为它们在每个时间上都被建模为有明确定义的高斯分布（均值，方差已指定）。因此，在VDM中，我们只关心学习条件概率 $p_θ(x_{t−1}|x_t)$ 以便进行数据模拟。由此，优化VDM的抽样过程就变得简单了。我们从 $p(x_T)$ 中抽样高斯噪声出发，利用去噪转换 $p_θ(x_{t−1}|x_t)$ 迭代地应用T步以生成新的 $x_0$ 。
与其他HVAE模型类似，VDM可以通过最大化Evidence Lower Bound (ELBO)来进行优化，其推导重新整理如下：
$$
\begin{align}
\log p(x)& = \log \int p(x_{0:T})dx_{1:T}  \tag{34} \\ 
&= \log \int \frac{p(x_{0:T})q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)}dx_{1:T} \tag{35}  \\
&= \log \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\frac{p(x_{0:T})}{q_(x_{1:T}|x_0)} \Big]  \tag{36} \\
&\geq \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\log{\frac{p(x_{0:T})}{q(x_{1:T}|x_0)}} \Big] \tag{37} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t) }{\prod_{t=1}^T q(x_t | x_{t-1})} \Big] \tag{38} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) \prod_{t=2}^T p_\theta(x_{t-1} | x_t) }{q(x_T | x_{T-1})\prod_{t=1}^{T-1} q(x_t | x_{t-1})} \Big] \tag{39} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) \prod_{t=1}^{T-1} p_\theta(x_t | x_{t+1})}{q(x_T | x_{T-1})\prod_{t=1}^{T-1} q(x_t | x_{t-1})} \Big] \tag{40} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1)}{q(x_T | x_{T-1})} \Big] + \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\log \prod_{t=1}^{T-1} \frac{p_\theta(x_t | x_{t+1})}{q(x_t | x_{t-1})} \Big] \tag{41} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} [\log p_\theta(x_0 | x_1)] + \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)}{q(x_T | x_{T-1})} \Big] + \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\sum_{t=1}^{T-1} \log \frac{p_\theta(x_t | x_{t+1})}{q(x_t | x_{t-1})} \Big] \tag{42} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} [\log p_\theta(x_0 | x_1)] + \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)}{q(x_T | x_{T-1})} \Big] + \sum_{t=1}^{T-1} \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\log \frac{p_\theta(x_t | x_{t+1})}{q(x_t | x_{t-1})} \Big] \tag{43} \\
&= \mathbb{E}_{q(x_1|x_0)} [\log p_\theta(x_0 | x_1)] + \mathbb{E}_{q(x_{T-1}，x_T|x_0)} \Big[ \log \frac{ p(x_T)}{q(x_T | x_{T-1})} \Big] + \sum_{t=1}^{T-1} \mathbb{E}_{q(x_{t-1},x_t,x_{t+1}|x_0)} \Big[ \log \frac{p_\theta(x_t | x_{t+1})}{q(x_t | x_{t-1})} \Big] \tag{44} \\
&= \underbrace{\mathbb{E}_{q(x_1|x_0)} [\log p_\theta(x_0 | x_1)]}_{重建项} - \underbrace{\mathbb{E}_{q(x_{T-1}|x_0)} [ D_{KL}(q(x_T|x_{T_1})||p(x_T))]}_{先验匹配项}
- \underbrace{\sum_{t=1}^{T-1} \mathbb{E}_{q(x_{t-1},x_{t+1}|x_0)}[D_{KL}(q(x_t|x_{t-1})||p(x_t|x_{t+1}))]}_{一致性项} \tag{45} \\

\end{align}
$$
***
译者言：公式43-44的推理，可用这种形式做，首先经过定理1将公式展开，这里 $q(x_{1:T}|x_0)$ 代表从 $x_0$ 开始，同时生成 $x_1, x_2,...,x_T$ 。因为这里的目标积分函数是连乘，且可以按照变量切分开，我们也可以拆开积分。
$$
\begin{align}
\mathbb{E}_{q(x_{1:T}|x_0)} [f(x_j)] &= \mathop{\int}_{x_{1:T}} \big[\prod_{t=1}^T q(x_t|x_0) \big]f(x_j)dx_{1:T} \\
&= \big[\prod_{t=1,t≠j}^T \mathop{\int}_{x_t} q(x_t|x_0)dx_t \big] \cdot \mathop{\int}_{x_j}q(x_j|x_0)f(x_j)dx_j \\
&=\big[ \prod_{t=1,t≠j}^T 1 \big] \cdot \mathop{\int}_{x_j}q(x_j|x_0)f(x_j)dx_j \\
&=\mathbb{E}_{q(x_j|x_0)} [f(x_j)]
\end{align}
$$
本质上是：非自变量并不会影响函数的期望。
在公式（45）中第二项，我们展开公式
$$
\begin{align}
\mathbb{E}_{q(x_{T-1}，x_T|x_0)} \Big[ \log \frac{ p(x_T)}{q(x_T | x_{T-1})} \Big]&= \iint q(x_{T-1},x_T|x_0) \Big[ \log \frac{p(x_T)}{q(x_T|x_{T-1})}\Big]dx_Tdx_{T-1} \\
&=\iint q(x_{T-1}|x_0)q(x_T|x_{T-1}) \Big[ \log \frac{p(x_T)}{q(x_T|x_{T-1})}\Big]dx_Tdx_{T-1} \\
&=\int q(x_{T-1}|x_0) \Big[\int q(x_T|x_{T-1})\log \frac{p(x_T)}{q(x_T|x_{T-1})}dx_T\Big]dx_{T-1} \\
&= \int q(x_{T-1}|x_0)[-D_{KL}(q(x_T|x_{T_1})||p(x_T))]dx_{T-1}\\
&=-\mathbb{E}_{q(x_{T-1}|x_0)} [ D_{KL}(q(x_T|x_{T_1})||p(x_T))]
\end{align}
$$
一致项推理类似。
***
推导出的ELBO可以从其三个组成部分进行第一轮解释：
1. 第一项 $\mathbb{E}_{q(x_1|x_0)} [\log p_\theta(x_0 | x_1)]$ 被称作重建项（reconstruction term）。它预测了给定第一步隐变量时原始数据样本的对数概率。这一项术语在传统的VAE中也存在，并且可以采用类似的训练方法。
2. 第二项 $\mathbb{E}_{q(x_{T-1}|x_0)} [ D_{KL}(q(x_T|x_{T_1})||p(x_T))]$ 被称为先验匹配项（prior matching term）。当最终的隐变量分布与高斯先验相匹配时（即隐变量接近纯高斯噪声），它被最小化。**这一项不需要进行优化，因为它也没有可训练的参数。** 我们可以想象，当T足够大时，最终的分布近似等于高斯分布，那么这一项效果上就趋近于零。
3. 第三项 $\mathbb{E}_{q(x_{t-1},x_{t+1}|x_0)}[D_{KL}(q(x_t|x_{t-1})||p(x_t|x_{t+1}))]$ 被称为一致性项（consistency term）。在每个中间时间步骤上，它要求从更噪声的图像进行去噪处理的结果应该与从更清晰的图像进行加噪处理的结果相匹配，即从前向和后向过程都要保持一致。在数学上，这通过KL散度来体现。当训练 $p_θ(x_t|x_{t+1})$使其与定义在公式式31中的高斯分布 $q(x_t|x_{t−1})$ 相匹配时，这一项被最小化。（此项需要训练优化）
![](images/1.2.4-2.png)
	*图4. 对于每个中间隐变量 $x_t$，匹配上面的后验 $p_θ(x_t|x_{t+1})$ 与之前的 $q(x_t|x_{t−1})$ 推理。VDM可以利用此方法进行优化 。在这个图中，对于每个中间的 $x_t$，我们最小化由粉色和绿色箭头表示的两分布之间的差异。*

结合图4的可视化结果看，优化VDM的值主要由第三项所主导，因为我们必须在所有时间步骤 $t$ 上进行优化。
根据这个推导，ELBO的所有项都可以通过期望值进行计算，因此可以使用蒙特卡洛估计来近似计算。然而，实际上使用我们刚刚推导出来的项来优化ELBO可能不是最优的；因为一致性项是对每个时间步骤计算两个随机变量 $\{x_{t−1},x_{t+1}\}$ 的期望，其蒙特卡洛估计的方差可能高于仅使用一个随机变量的项的方差。由于它是通过求和 $T−1$ 个一致性项得到的，对于较大的 $T$ 值，ELBO的最终估计值可能具有较高的方差。
***
译者言：$T-1$ 的说法来自样本方差公式，大学概率论教材都会解释样本方差 $n-1$ 自由度的来历。
$$
S^2=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\overline{X})^2
$$
但作者这里写得比较隐晦。我看了半天（As it is computed by summing up T −1 consistency terms, the final estimated value of the ELBO may have high variance for large T values.）... ，额，没错，他就是想说我这个意思。只不过中国人已经学过了，他这么一提反而让人感到奇怪，而且蒙特卡洛估计怎么做在本文中并不重要。
***
我们尝试推导ELBO的一个形式，其中每个项作为一个随机变量的期望只计算一次。关键的见解是，我们可以将编码器的转换重写为 $q(x_t|x_{t−1})=q(x_t|x_{t−1},x_0)$ ，由于马尔可夫性质，额外的条件项是多余的。然后，根据贝叶斯规则，我们可以将每个转换重写为：
$$
q(x_t|x_{t−1})=q(x_t|x_{t−1},x_0)=\frac{q(x_{t-1}|x_t,x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)} \tag{46}
$$
有了这个新的公式，我们重新开始公式（37）中的ELBO推导可得：
$$
\begin{align}
\log p(x)&\geq \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\log{\frac{p(x_{0:T})}{q(x_{1:T}|x_0)}} \Big] \tag{47} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t) }{\prod_{t=1}^T q(x_t | x_{t-1})} \Big] \tag{48} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) \prod_{t=2}^T p_\theta(x_{t-1} | x_t) }{q(x_1 | x_0) \prod_{t=2}^{T} q(x_t | x_{t-1})} \Big] \tag{49} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) \prod_{t=2}^T p_\theta(x_{t-1} | x_t) }{q(x_1 | x_0)\prod_{t=2}^{T} q(x_t | x_{t-1},x_0)} \Big] \tag{50} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) }{q(x_1 | x_0)} + \log \prod_{t=2}^{T} \frac{p_\theta(x_{t-1} | x_t)}{ q(x_t | x_{t-1},x_0)} \Big] \tag{51} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) }{q(x_1 | x_0)} + \log \prod_{t=2}^{T} \frac{p_\theta(x_{t-1} | x_t)}{\frac{q(x_{t-1}|x_t,x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}} \Big] \tag{52} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) }{q(x_1 | x_0)} + \log \prod_{t=2}^{T} \frac{p_\theta(x_{t-1} | x_t)}{\frac{q(x_{t-1}|x_t,x_0) \cancel{q(x_t|x_0)}}{\cancel{q(x_{t-1}|x_0)}}} \Big] \tag{53} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) }{\cancel{q(x_1 | x_0)}} + \log\frac{\cancel{q(x_1|x_0)}}{q(x_T|x_0)} +\log \prod_{t=2}^{T} \frac{p_\theta(x_{t-1} | x_t)}{q(x_{t-1}|x_t,x_0)} \Big] \tag{54} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{ p(x_T)p_\theta(x_0 | x_1) }{q(x_T | x_0)}  + \sum_{t=2}^{T}  \log  \frac{p_\theta(x_{t-1} | x_t)}{q(x_{t-1}|x_t,x_0)} \Big] \tag{55} \\
&= \mathbb{E}_{q(x_{1:T}|x_0)} [ \log p_\theta(x_0 | x_1)] + \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{p(x_T)}{q(x_T | x_0)}\Big]  + \sum_{t=2}^{T} \mathbb{E}_{q(x_{1:T}|x_0)} \Big[ \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_{t-1}|x_t,x_0)} \Big] \tag{56} \\
&= \mathbb{E}_{q(x_{1}|x_0)} [ \log p_\theta(x_0 | x_1)] + \mathbb{E}_{q(x_{T}|x_0)} \Big[ \log \frac{p(x_T)}{q(x_T | x_0)}\Big]  + \sum_{t=2}^{T} \mathbb{E}_{q(x_t,x_{t-1}|x_0)} \Big[ \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_{t-1}|x_t,x_0)} \Big] \tag{57} \\
&= \underbrace{\mathbb{E}_{q(x_{1}|x_0)} [ \log p_\theta(x_0 | x_1)]}_{重建项} -   \underbrace{D_{KL}(q(x_T|x_0)||p(x_T))}_{先验匹配项} - \underbrace{\sum_{t=2}^{T} \mathbb{E}_{q(x_t|x_0)} [D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t))]}_{去噪匹配项} \tag{58}
\end{align}
$$
***
译者言：公式（53）使用采用错位消去法。我们网上看到推理公式，最多使用这种版本。
***

因此，我们成功地对ELBO进行了解释，并且可以通过一次只计算一个随机变量的期望来进行估计，从而降低了方差。这种形式也有一个优雅的解释，当我们仔细检查每个单独的项时，就会揭示出：
1. $\mathbb{E}_{q(x_{1}|x_0)} [ \log p_\theta(x_0 | x_1)]$ 是重建项（reconstruction term），与传统VAE中的ELBO类似，这个项可以使用蒙特卡洛估计进行近似和优化。（译者言：因为此时还有 $\theta$）
2. $D_{KL}(q(x_T|x_0)||p(x_T))$ 代表最终加入噪声的分布与标准高斯先验（译者言：$p(x_T)$ 已经变成标准高斯噪声了）之间的接近程度。它没有可训练的参数，并且根据我们的假设（纯标准高斯噪声）也等于零。
3. $\mathbb{E}_{q(x_t|x_0)} [D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t))]$ 是去噪匹配项（denoising matching term）。我们希望学习去噪步骤$p_θ(x_{t−1}|x_t,x_0)$ 去近似ground-truth真实去噪转换步骤 $q(x_{t−1}|x_t,x_0)$ 。由于 $q(x_{t−1}|x_t,x_0)$ 可以作为一个ground-truth信号。它定义了如何将带噪声的图像 $x_t$ 去噪成完全图像 $x_0$。当两种去噪分布尽可能地匹配时，这个KL散度项就会被最小化。

附带说明，在推导ELBO（公式（45）和公式（58））的过程解释中，只使用了马尔可夫假设；因此，这些公式对于任意任意的MHVAE都是成立的。此外，当我们将 $T=1$ 时，VDM的这两种ELBO解释恰好与传统VAE的ELBO方程（公式（19））完全一致。
在这个ELBO的推导中，优化成本的大部分仍然在求和项中，这主要取决于重建项。而每个KL散度项$D_{KL}(q(x_{t−1}|x_t,x_0)‖ p_\theta(x_{t−1}|x_t))$ ，由于还有学习编码器的需要而增加训练复杂度的情况。此时，对于任意复杂的MHVAE来说，我们还是很难在没有其他条件下使其最小化。但在VDM中，我们可以利用高斯状态转移的假设来使优化变得可行。根据上面贝叶斯定理，公式（46），我们有：       
$$
q(x_{t−1}|x_t,x_0)= \frac{q(x_t|x_{t−1}, x_0)q(x_{t−1}|x_0)}{q(x_t|x_0)}
$$
我们从编码转换假设（公式（31））中已经知道 $q(x_{t−1}|x_t,x_0)=q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{\alpha_t}x_{t-1},(1-\alpha_t)I)$ ，上面公式中还剩下的是 $q(x_t|x_0)$ 和 $q(x_{t-1}|x_0)$ 这两项。幸运的是，这些也因为VDM是线性高斯模型而已经变得易于处理。回想一下，在重参数化技巧下，样本 $x_t∼q(x_t|x_{t−1})$ 可以改写为：
$$
\begin{align}
x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon \tag{59} \\
\text{with}: \epsilon \sim \mathcal{N}(\epsilon;0,I) 
\end{align}
$$
类似 $x_{t-1}∼q(x_{t-1}|x_{t−2})$可以重写为：
$$
\begin{align}
x_{t-1} = \sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon \tag{60} \\
\text{with}: \epsilon \sim \mathcal{N}(\epsilon;0,I) 
\end{align}
$$
然后，通过反复应用重参数化技巧，可以递归地导出 $q(x_t|x_0)$ 的形式。假设我们有 $2T$ 个各自独立同分布的随机噪声变量 $\{\epsilon_t^∗,\epsilon_t\}_{t=0}^{T}\sim \mathcal{N}(\epsilon;0,I)$ 。那么，对于任意的样本 $x_t∈q(x_t|x_0)$ ，我们可以将其改写为：
$$
\begin{align}
x_t&=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t-1}^* \tag{61} \\
&=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}\epsilon_{t-2}^*)+\sqrt{1-\alpha_t}\epsilon_{t-1}^* \tag{62} \\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\epsilon_{t-2}^*+\sqrt{1-\alpha_t}\epsilon_{t-1}^* \tag{63} \\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+ \sqrt{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}^2+\sqrt{1-\alpha_t}^2}\epsilon_{t-2}\tag{64} \\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+ \sqrt{\alpha_t-\alpha_t\alpha_{t-1}+1-\alpha_t}\epsilon_{t-2}\tag{65} \\
&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+ \sqrt{1-\alpha_t\alpha_{t-1}}\epsilon_{t-2}\tag{66} \\
&=... \tag{67} \\
&=\sqrt{\prod_{i=1}^t \alpha_i}x_0 + \sqrt{1-\prod_{i=1}^t \alpha_i}\epsilon_0 \tag{68} \\
&=\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1-\overline{\alpha}_t}\epsilon_0 \tag{69} \\
&\sim \mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I) \tag{70}
\end{align}
$$
（译者言：这里的 $\bar\alpha_t = \prod_{i=1}^t \alpha_i$ ，代指连乘，而不是平均值的意思）
在公式64中，我们利用了两个独立高斯随机变量相加的高斯分布计算方法。其结果仍然是一个均值为均值之和（这里为0）、方差为方差之和的高斯分布。 $\sqrt{1−α_t}\epsilon_{t-1}^*$ 可解释为从高斯分布 $\mathcal{N}(0,(1−\alpha_t)I)$ 中取样， $\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\epsilon_{t-2}^*$ 可解释为从高斯分布 $\mathcal{N}(0,(α_t−α_tα_{t−1})I)$ 中取样，因此我们可以将它们的和视为从高斯分布 $\mathcal{N}(0,(1−α_t+α_t−α_tα_{t−1})I)=\mathcal{N}(0,(1−α_tα_{t−1})I)$ 中取样得到的随机变量。从这个分布中取样，公式（64）可以使用重参数化技巧为 $\sqrt{1−α_tα_{t−1}}\epsilon_{t−2}$ ，如公式（66）所示。
我们已经得到了 $q(x_t|x_0)$ 的高斯分布形式。这个推导经修改就得到描述 $q(x_{t−1}|x_0)$ 的高斯分布参数化形式。现在，我们已经知道了 $q(x_t|x_0)$ 和 $q(x_{t−1}|x_0)$ 的形式，我们可以通过将其代入贝叶斯规则展开来继续计算 $q(x_{t−1}|x_t,x_0)$ ：
$$
\begin{align}
q(x_{t−1}|x_t,x_0) &= \frac{q(x_t|x_{t−1}, x_0)q(x_{t−1}|x_0)}{q(x_t|x_0)} \tag{71}\\
&=\frac{\mathcal{N}({{x}}_t;\sqrt{{\alpha}_t}{{x}}_{t-1},(1-{\alpha}_t){{I}})\mathcal{N}({{x}}_{t-1};\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0},(1-\bar{{\alpha}}_{t-1}){{I}})}{\mathcal{N}({{x}}_{t};\sqrt{\bar{{\alpha}}_{t}}{{x}}_{0},(1-\bar{{\alpha}}_{t}){{I}})} \tag{72} \\
&\propto \exp\left\{ -\left[\frac{({{x}}_t-\sqrt{{\alpha}_t}{{x}}_{t-1})^2}{2(1-{\alpha}_t)}+\frac{({{x}}_{t-1}-\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0})^2}{2(1-\bar{{\alpha}}_{t-1})}-\frac{({{x}}_{t}-\sqrt{\bar{{\alpha}}_{t}}{{x}}_{0})^2}{2(1-\bar{{\alpha}}_{t})}\right]\right\} \tag{73}\\
&= \exp\left\{ -\frac{1}{2}\left[\frac{({{x}}_t-\sqrt{{\alpha}_t}{{x}}_{t-1})^2}{1-{\alpha}_t}+\frac{({{x}}_{t-1}-\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0})^2}{1-\bar{{\alpha}}_{t-1}}-\frac{({{x}}_{t}-\sqrt{\bar{{\alpha}}_{t}}{{x}}_{0})^2}{1-\bar{{\alpha}}_{t}}\right]\right\} \tag{74}\\
&= \exp\left\{ -\frac{1}{2}\left[\frac{-2\sqrt{{\alpha}_t}{{x}}_t {{x}}_{t-1}+{\alpha}_t {{x}}_{t-1}^2}{1-{\alpha}_t}+\frac{{{x}}_{t-1}^2 2\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{t-1}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}} +C({{x}}_t,{{x}}_0)\right]\right\} \tag{75}\\
& \propto \exp\left\{ -\frac{1}{2}\left[-\frac{2\sqrt{{\alpha}_t}{{x}}_t {{x}}_{t-1}}{1-{\alpha}_t} + \frac{{\alpha}_t {{x}}_{t-1}^2}{1-{\alpha}_t} + \frac{{{x}}_{t-1}^2}{1-\bar{{\alpha}}_{t-1}} - \frac{2\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{t-1}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right]\right\} \tag{76}\\
&=\exp\left\{ -\frac{1}{2}\left[\left(\frac{{\alpha}_t }{1-{\alpha}_t} + \frac{1}{1-\bar{{\alpha}}_{t-1}}\right){{x}}_{t-1}^2 - 2\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right) {{x}}_{t-1}\right]\right\} \tag{77}\\
&=\exp\left\{ -\frac{1}{2}\left[\frac{{\alpha}_t(1-\bar{{\alpha}}_{t-1})+1-{\alpha}_t}{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{{x}}_{t-1}^2 -  2\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right) {{x}}_{t-1}\right]\right\} \tag{78}\\
&=\exp\left\{ -\frac{1}{2}\left[\frac{{\alpha}_t-\bar{{\alpha}}_{t}+1-{\alpha}_t}{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{{x}}_{t-1}^2 - 2\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right) {{x}}_{t-1}\right]\right\} \tag{79}\\
&=\exp\left\{ -\frac{1}{2}\left[\frac{1-\bar{{\alpha}}_{t}}{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{{x}}_{t-1}^2 - 2\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right) {{x}}_{t-1}\right]\right\} \tag{80}\\
&={\exp\left\{ -\frac{1}{2} \left(\frac{1-\bar{{\alpha}}_{t}}{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})} \right) {\left[x_{t-1}^2 - 2\frac{\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right)}{\frac{1-\bar{\alpha}_t}{(1-\alpha)(1-\bar{\alpha}_{t-1})}} x_{t-1}\right]}\right\}} \tag{81}\\
&={\exp\left\{ -\frac{1}{2} \left(\frac{1-\bar{{\alpha}}_{t}}{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})} \right) {\left[x_{t-1}^2 - 2\frac{\left(\frac{\sqrt{{\alpha}_t}{{x}}_t}{1-{\alpha}_t} + \frac{\sqrt{\bar{{\alpha}}_{t-1}}{{x}}_{0}}{1-\bar{{\alpha}}_{t-1}}\right)(1-\alpha)(1-\bar{\alpha}_{t-1}) }{1-\bar{\alpha}_t} x_{t-1}\right]}\right\}} \tag{82}\\
&=\exp\left\{ -\frac{1}{2} \left(\frac{1}{\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}}} \right)\\ \quad \left[ {{x}}_{t-1}^2-2\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} {{x}}_{t-1}\right]\right\} \tag{83}\\
&\propto \mathcal{N}({{x}}_{t-1};\underbrace{\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}}}_{{{\mu}}_q({{x}}_t,{{x}}_0)},\underbrace{\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}}}_{{{\Sigma}}_{q}(t)}) \tag{84}
\end{align} 
$$
在公式（75）中，$C(x_t,x_0)$仅由 $x_t$ 、$x_0$和 $\alpha$ 值的组合计算得出，是关于 $x_{t−1}$ 的常数项。这个项在公式（84）中隐含地返回，以匹配完成正态分布的平方项。
由此在我们已经展示的每个步骤中，$x_{t−1}∼q(x_{t−1}|x_t,x_0)$ 服从正态分布，其均值 $μ_q(x_t,x_0)$ 是$x_t、x_0$ 的函数，方差 $Σ_q(t)$ 是 $\alpha$ 系数的函数。这些 $\alpha$ 系数在每个时间步长上是已知且固定的；它们要么被固定为超参数，要么被视为某种网络推理的结果。根据公式（84），我们可以将方差公式写为 $\sum_q(t)=σ_q^2(t)I$ ，其中：
$$
σ_q^2(t)=\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} \tag{85}
$$
为了尽可能地将**近似去噪分布** $p_θ(x_{t−1}|x_t)$ 与**真值去噪分布** $q(x_{t−1}|x_t,x_0)$ 相匹配，我们也可以将两者都建模为高斯模型。此外，由于在每个时间层中所有的 $\alpha$ 项都被固定了，根据公式（85）我们可以立即构造**近似去噪分布**的方差。由于 $p_θ(x_{t−1}|x_t)$ 不依赖于 $x_0$，我们将**近似去噪分布**均值 $μ_θ(x_t,t)$ 参数化为 $x_t$ 的函数。(译者言，**近似去噪分布**类似是噪声预测，压根没有 $x_0$ )
回顾两个高斯分布之间的KL散度为：
$$
D_{KL}(\mathcal{N}(x;\mu_x,\Sigma_x)||\mathcal{N}(y;\mu_y,\Sigma_y))=\frac{1}{2}\Big[\log \frac{\Sigma_y}{\Sigma_x} -d+ tr(\Sigma_y^{-1}\Sigma_x) + (\mu_y-\mu_x)^T\Sigma_y^{-1}(\mu_y-\mu_x)\Big] \tag{86}
$$
在我们的例子中，我们可以让两个高斯分布的方差精确匹配。根据如下公式，优化KL散度项可以归结为最小化两个分布的均值之差，请看推理过程：
$$
\begin{align}
&~~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q({{x}}_{t-1}|{{x}}_t,{{x}}_0)\Vert p_{{\theta}}({{x}}_{t-1}|{{x}}_t)) \\
&=\arg\min_{{{\theta}}} D_{\text{KL}}(\mathcal{N} ({{x}}_{t-1}; {\mu}_q, Σ_q(t)) \Vert \mathcal{N} ({{x}}_{t-1}; {\mu}_{{\theta}}, Σ_q(t))) \tag{87} \\
&={\arg\min_{{{\theta}}} \frac{1} {2} \left[ \log \frac{|Σ_q(t)|} {|Σ_q(t)|} − d +\\ tr(Σ_q^{−1}(t) Σ_q(t)) + ({\mu}_{{\theta}} − {\mu}_q)^\top Σ^{−1}_q ({\mu}_{{\theta}} − {\mu}_q) \right] }\tag{88}\\
&=\arg\min_{{{\theta}}} \frac{1} {2} \left[ \log 1− d + d + ({\mu}_{{\theta}} − {\mu}_q)^\top Σ^{−1}_q ({\mu}_{{\theta}} − {\mu}_q) \right] \tag{89}\\
&=\arg\min_{{{\theta}}} \frac{1} {2} \left[ ({\mu}_{{\theta}} − {\mu}_q)^\top Σ^{−1}_q ({\mu}_{{\theta}} − {\mu}_q) \right] \tag{90}\\
&=\arg\min_{{{\theta}}} \frac{1} {2} \left[ ({\mu}_{{\theta}} − {\mu}_q)^\top (σ_q^2 (t) {{I}})^{-1} ({\mu}_{{\theta}} − {\mu}_q) \right] \tag{91}\\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Vert {\mu}_{{\theta}} − {\mu}_q \Vert_2^2 \right] \tag{92}\\
\end{align}
$$
其中，$μ_q$ 为**真值去噪分布**的均值 $μ_q(x_t,x_0)$ 的简写，$μ_θ$ 为**近似去噪分布**的均值 $μ_θ(x_t,t)$ 的简写，以示简洁。换句话说，我们想要优化一个与$μ_q(x_t,x_0)$ 相匹配的 $μ_θ(x_t,t)$ ，该 $μ_q(x_t,x_0)$ 取自我们推导的公式（84）：
$$
\mu_q(x_t,x_0)=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} \tag{93}
$$
由于 $μ_θ(x_t,t)$ 也是依赖于 $x_t$ ，因此我们可以紧密匹配 $μ_q(x_t,x_0)$ ，设置为如下形式：
$$
\mu_\theta(x_t,t)=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\hat{x}_\theta(x_t,t)}{1-\bar{{\alpha}}_{t}} \tag{94}
$$
其中，$\hat{x}_θ(x_t,t)$ 由一个神经网络建模，该神经网络试图从含噪图像 $x_t$ 和时间索引 $t$ 预测 $x_0$。然后，优化问题简化为：
$$
\begin{align}
&~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q({{x}}_{t-1}|{{x}}_t,{{x}}_0)\Vert p_{{\theta}}({{x}}_{t-1}|{{x}}_t))\\
&=\arg\min_{{{\theta}}} D_{\text{KL}}(\mathcal{N} ({{x}}_{t-1}; μ_q, Σ_q(t)) \Vert \mathcal{N} ({{x}}_{t-1}; μ_{{\theta}}, Σ_q(t))) \tag{95} \\
&=\arg\min_{{{\theta}}} \frac{1} {2σ_q^2 (t)} \left[\left \Vert\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)}{1-\bar{{\alpha}}_{t}}\\ -\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} \right \Vert_2^2\right] \tag{96}\\
&=\arg\min_{{{\theta}}} \frac{1} {2σ_q^2 (t)} \left[\left \Vert\frac{\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)}{1-\bar{{\alpha}}_{t}}-\frac{\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} \right \Vert_2^2\right] \tag{97}\\
&=\arg\min_{{{\theta}}} \frac{1} {2σ_q^2 (t)} \left[\left \Vert\frac{\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)}{1-\bar{{\alpha}}_{t}}(\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)-{{x}}_{0}) \right \Vert_2^2\right] \tag{98}\\
&=\arg\min_{{{\theta}}} \frac{1} {2σ_q^2 (t)}\frac{\bar{{\alpha}}_{t-1}(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_{t})^2} \left[\left \Vert\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)-{{x}}_{0} \right \Vert_2^2\right] \tag{99}\\
\end{align}
$$
由此可知，优化VDM可归结为学习“从任意被高斯分布噪声化的图片中预测原始的真实图像”的神经网络。此外，最小化我们推理出的ELBO目标（公式（58））的求和项，可以通过最小化各时间步的期望来近似：
$$
\arg \min_{\theta} \mathbb{E}_{t\sim U\{2,T\}} [\mathbb{E}_{q(x_t|x_0)}[D_{KL}(q(x_{t−1}|x_t, x_0) || p_θ(x_{t−1}|x_t))]] \tag{100}
$$
该公式可以利用各时间步的随机采样值进行优化。

### 1.2.5 学习扩散模型噪声参数
让我们来探讨如何联合学习VDM的噪声参数。一种方法是使用一个具有参数η的神经网络$\hatα_η(t)$ 来建模 $\alpha_t$ 。然而，这种方法效率较低，因为在每个时间步 $t$ 中需要进行多次推理才能累积计算出 $\bar α_t$ 。虽然可以通过缓存来减少这种计算成本，但我们也可以找到一种替代方式来学习扩散噪声参数。通过将公式（85）中的方差公式代入公式（99）中可以得到的每个时间步目标函数，我们接着公式（99）可以计算出：
$$
\begin{align}
\frac{1} {2σ_q^2 (t)}\frac{\bar{{\alpha}}_{t-1}(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_{t})^2} \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right]&=\frac{1} {2\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} }\frac{\bar{{\alpha}}_{t-1}(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_{t})^2} \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{101}\\
&=\frac{1}{2}\frac{1-\bar{{\alpha}}_{t}} {(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1}) }\frac{\bar{{\alpha}}_{t-1}(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_{t})^2} \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{102}\\
&=\frac{1}{2}\frac{\bar{\alpha}_{t-1}(1-{\alpha}_t)}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t}) } \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{103}\\
&=\frac{1}{2}\frac{\bar{\alpha}_{t-1}-\bar{\alpha}_t}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t}) } \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{104}\\
&=\frac{1}{2}\frac{\bar{\alpha}_{t-1}- \bar{\alpha}_{t-1}\bar{\alpha}_t+ \bar{\alpha}_{t-1}\bar{\alpha}_t - \bar{\alpha}_t}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t}) } \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{105}\\
&=\frac{1}{2}\frac{\bar{\alpha}_{t-1}(1- \bar{\alpha}_t)- \bar{\alpha}_t(1- \bar{\alpha}_{t-1})}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t}) } \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{106}\\
&=\frac{1}{2} \Big(\frac{\bar{\alpha}_{t-1}(1- \bar{\alpha}_t)}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t})}  - \frac{\bar{\alpha}_t(1- \bar{\alpha}_{t-1})}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t})}\Big) \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{107}\\
&=\frac{1}{2} \Big(\frac{\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t-1}}  - \frac{\bar{\alpha}_t}{1-\bar{{\alpha}}_{t}}\Big) \left[\left \Vert\hat{{x}}_{{\theta} }({x}_t,t)-{x}_{0} \right \Vert_2^2\right] \tag{108}\\
\end{align}
$$
回到公式（70），$q(x_t|x_0)$ 是一个高斯分布 $\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)$ 。下面我们定义信噪比（signal-to-noise ratio，SNR）$SNR=\frac{\mu^2}{\sigma^2}$ ，（译者言，这是信噪比的另一种定义方式，意思是到标准差信号的比率）在每个时间 $t$ 上，我们重写SNR如下：
$$
\text{SNR}(t)=\frac{\bar{\alpha}_t}{1-\bar{\alpha}_t} \tag{109}
$$

代回公式（108，99），可以被简化为：
$$
\frac{1} {2σ_q^2 (t)}\frac{\bar{{\alpha}}_{t-1}(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_{t})^2} \left[\left \Vert\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)-{{x}}_{0} \right \Vert_2^2\right]=\frac{1}{2}(\text{SNR}(t-1)-\text{SNR}(t)) \left[\left \Vert\hat{{{x}}}_{{{\theta}} }({{x}}_t,t)-{{x}}_{0} \right \Vert_2^2\right] \tag{110}
$$
正如其名称所示，信噪比SNR表示原始信号与噪声的比值；较高的SNR表示更多的信号，较低的SNR表示更多的噪声。在扩散模型中，我们要求随着时间步 $t$ 的增加，SNR单调减小。这形式化了一个观念，即输入 $x_t$ 随着时间的推移变得越来越嘈杂，直到在 $t=T$ 时变得与标准高斯分布相同。
根据公式（110）中目标函数的简化，我们可以直接使用神经网络在每个时间步骤参数化SNR，并且与扩散模型一起进行联合学习。由于SNR必须随着时间的推移单调减小，我们可以表示为：
$$
\text{SNR}(t)=\exp(-\omega_\eta(t)) \tag{111}
$$
如果含有参数η的 $𝜔_𝜂(𝑡)$ 被建模成单调递增神经网络，那么负的 $𝜔_𝜂(𝑡)$ 是一个单调递减的函数。公式（111）中由于定义SNR为指数运算，所以结果始终为正数。注意，在公式（100）中的目标函数现在还必须针对参数η进行优化。将对SNR的参数化（公式（111）中）与对SNR的定义（公式（109）中）相结合，我们也可以明确推导出关于 $\bar{𝛼}_𝑡$ 的形式以及关于 $1−\bar{α}_𝑡$ 的值：
$$
\begin{align}
\frac{\bar{\alpha}_t}{1-\bar{\alpha}_t}&=\exp(-\omega_\eta(t)) \tag{112} \\
\therefore \bar{\alpha}_t &=\text{sigmoid}(-\omega_\eta(t)) \tag{113} \\
\therefore 1-\bar{\alpha}_t &=\text{sigmoid}(\omega_\eta(t)) \tag{114}
\end{align}
$$
上面公式在各种计算中都是必需的。例如，在优化过程中常常从 $x_0$ 中创建任意噪声 $𝑥_𝑡$ ，上面公式常常用于重参数化，具体推导见公式（69）。

## VDM的三种优化策略
正如我们先前证明的，VDM可以通过简单的神经网络来训练，从杂乱噪声 $x_t$ 开始，经过t步来预测原始图像 $x_0$ 。然而 $x_0$ 还有两个等效参数，这就引出了VDM两个等效优化策略。
在第一种解释中，我们利用重参数技巧，将 $q(x_t|x_0)$ 的推导中的等式（69）变成：
$$
x_0 = \frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}
$$
代入公式（93）推导的真实去噪转移均值 $μ_𝑞(𝑥_𝑡,𝑥_0)$ ，我们可以重新推导为：
$$
\begin{align}
\mu_q(x_t,x_0)&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} \tag{116} \\
&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}}{1-\bar{{\alpha}}_{t}} \tag{117} \\
&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+(1-{\alpha}_t)\frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\alpha_t}}}{1-\bar{{\alpha}}_{t}} \tag{118} \\
&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t}{1-\bar{{\alpha}}_{t}} +
\frac{(1-{\alpha}_t)x_t}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}} - \frac{(1-{\alpha}_t)\sqrt{1-\bar{\alpha}_t}\epsilon_0}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}} \tag{119} \\
&=\Big(\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} +
\frac{1-{\alpha}_t}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}}\Big)x_t - \frac{(1-{\alpha}_t)\sqrt{1-\bar{\alpha}_t}}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}}\epsilon_0 \tag{120} \\
&= \Big(\frac{{\alpha}_t(1-\bar{{\alpha}}_{t-1})}{(1-\bar{{\alpha}}_{t})\sqrt{\alpha}_t} +
\frac{1-{\alpha}_t}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}}\Big)x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{121} \\
&= \frac{\alpha_t - \bar{\alpha}_t+1-{\alpha}_t}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{122} \\
&= \frac{1 - \bar{\alpha}_t}{(1-\bar{{\alpha}}_t)\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{123} \\
&= \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{124} \\
\end{align}
$$
因此，我们可以设置近视去噪均值 $\mu_\theta(x_t,t)$ 为：
$$
\mu_\theta(x_t,t) = \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(x_t,t) \tag{125}
$$
公式（87-92）中相应的优化问题将变成：
$$
\begin{align}
&~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q({{x}}_{t-1}|{{x}}_t,{{x}}_0)\Vert p_{{\theta}}({{x}}_{t-1}|{{x}}_t))\\
&=\arg\min_{{{\theta}}} D_{\text{KL}}(\mathcal{N} ({{x}}_{t-1}; μ_q, Σ_q(t)) \Vert \mathcal{N} ({{x}}_{t-1}; μ_{{\theta}}, Σ_q(t))) \tag{126} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Vert {\mu}_{{\theta}} − {\mu}_q \Vert_2^2 \right] \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(x_t,t) − \frac{1}{\sqrt{\alpha_t}}x_t + \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \Big\Vert_2^2 \right] \tag{127} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(x_t,t) \Big\Vert_2^2 \right] \tag{128} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}(\epsilon_0 - \hat{\epsilon}_\theta(x_t,t)) \Big\Vert_2^2 \right] \tag{129} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \frac{(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_t)\alpha_t} \left[ \Big\Vert (\epsilon_0 - \hat{\epsilon}_\theta(x_t,t)) \Big\Vert_2^2 \right] \tag{130} \\
\end{align}
$$
这里，$\hat{\epsilon}_\theta(x_t,t)$ 是一个用源噪声 $\epsilon_0 \sim \mathcal{N}(\epsilon;0,I)$ 指导 $x_t$ 到 $x_0$ 生成的神经网络。因此，我们已经证明通过预测原始图像 $𝑥_0$ 来学习 VDM 等同于学习预测噪声。一些研究实证发现预测噪声可以得到更好的结果。

为了得出变分扩散模型的第三种通用解释，我们引入 Tweedie 公式。Tweedie 公式指出，在给定样本的条件下，指数族分布（exponential family distribution）的真实均值可以通过样本的最大似然估计（也称为经验均值）加上一些涉及估计分数的校正项来估计。当只有一个观察样本时，经验均值就是样本本身。这通常用于减轻样本偏差；如果观察样本全都位于基础分布的一端，那么负的分数会变大，并将最大似然估计修正向真实均值方向。
从数学上讲，对于满足高斯分布的变量 $𝑧 \sim \mathcal{𝑁}(𝑧;μ_𝑧,Σ_𝑧)$，Tweedie 公式如下：
$$
\mathbb{𝐸}[𝜇_𝑧|𝑧]=𝑧+𝛴_𝑧∇_𝑧 \log⁡ 𝑝(𝑧)
$$
***
译者言：Tweedie 公式来自贝叶斯估计。贝叶斯估计的问题定义为根据一些观测数据 $𝑥$ 来估计未知参数 $𝜃$，如果用均方误差(MSE)损失函数来衡量估计的准确性的话，我们将问题建模为：
$$
L= \mathbb{E}[(\hat{\theta}(x)-\theta)^2]
$$
整个问题本质其实就是求解， $x$ 的条件下， $\theta$ 值的期望：
$$
\hat{\theta}(x)=\mathbb{E}[\theta|x]=\int \theta p(\theta|x)d\theta
$$
而Tweedie公式，就是一种估计 $\theta$ 的方案。假设 $p(x|\theta)=\mathcal{N}(\theta,\sigma^2)$，可以通过观测数据估计出参数𝜎，则有：
$$
\begin{align}
\hat{\theta}(x)=\mathbb{E}[\theta|x] &=\int \theta p(\theta|x)d\theta \\
&= x+\sigma^2\frac{d}{dx} \log p(x)
\end{align}
$$
这个公式的优点是一直保有着 $𝑝(𝜃)$ 的雏形而没有探究它的具体样子。此公式专供已知方差，求不出来均值时使用。
***

在这种情况下，我们应用它来预测给定样本的 $𝑥_𝑡$ 的真实后验均值。由公式（70）可知：
$$
q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)
$$
（译者言，这就是方差很好求，均值有 $x_0$ 太难求的例子）利用Tweedie公式，我们得出：
$$
\mathbb{𝐸}[𝜇_{x_t}|x_t]=x_t+(1-\bar{\alpha}_t)∇_{x_t} \log⁡ 𝑝(x_t) \tag{131}
$$
其中，为了符号的简洁性，我们将 $∇_{x_t}\log p(x_t)$ 写为 $∇ \log p(x_t)$ 。根据 Tweedie 公式，由 $𝑥_𝑡$ 生成的真实均值 $μ_{𝑥_𝑡}=\sqrt{\bar{α}_t}𝑥_0$ ，可定义为：
$$
\begin{align}
\sqrt{\bar{α}_t}𝑥_0 &= x_t+(1-\bar{\alpha}_t)∇_{x_t} \log⁡ 𝑝(x_t) \tag{132} \\
\therefore x_0 &= \frac{x_t+(1-\bar{\alpha}_t)∇_{x_t} \log⁡ 𝑝(x_t)} {\sqrt{\bar{α}_t}} \tag{133}
\end{align}
$$
然后，我们可以将公式133再次代入我们的真实去噪转移均值 $μ_𝑞(𝑥_𝑡,𝑥_0)$并推导出新的形式：
$$
\begin{align}
\mu_q(x_t,x_0) &=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}} 
\tag{134} \\
&= \frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\frac{x_t+(1-\bar{\alpha}_t)∇ \log⁡ 𝑝(x_t)} {\sqrt{\bar{α}_t}} }{1-\bar{{\alpha}}_{t}} \tag{135} \\
&= \frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+(1-{\alpha}_t)\frac{x_t+(1-\bar{\alpha}_t)∇ \log⁡ 𝑝(x_t)} {\sqrt{α_t}} }{1-\bar{\alpha}_{t}} \tag{136} \\
&= \frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t}{1-\bar{\alpha}_{t}} +
\frac{(1-{\alpha}_t)x_t}{(1-\bar{\alpha}_{t})\sqrt{α_t}} + \frac{(1-\alpha_t)(1-\bar{\alpha}_t)∇ \log⁡ 𝑝(x_t) }{(1-\bar{\alpha}_{t})\sqrt{α_t}} \tag{137} \\
&= \Big(\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})}{1-\bar{\alpha}_{t}} +
\frac{1-{\alpha}_t}{(1-\bar{\alpha}_{t})\sqrt{α_t}} \Big)x_t+ \frac{1-\alpha_t}{\sqrt{α_t}}∇ \log⁡ 𝑝(x_t) \tag{138} \\
&= \Big(\frac{{\alpha}_t(1-\bar{{\alpha}}_{t-1})}{(1-\bar{\alpha}_{t})\sqrt{{\alpha}_t}} +
\frac{1-{\alpha}_t}{(1-\bar{\alpha}_{t})\sqrt{α_t}} \Big)x_t+ \frac{1-\alpha_t}{\sqrt{α_t}}∇ \log⁡ 𝑝(x_t) \tag{139} \\
&= \frac{{\alpha}_t -\bar{{\alpha}}_{t}+ 1-{\alpha}_t}{(1-\bar{\alpha}_{t})\sqrt{α_t}}x_t+ \frac{1-\alpha_t}{\sqrt{α_t}}∇ \log⁡ 𝑝(x_t) \tag{140} \\
&= \frac{ 1-\bar{{\alpha}}_{t}}{(1-\bar{\alpha}_{t})\sqrt{α_t}}x_t+ \frac{1-\alpha_t}{\sqrt{α_t}}∇ \log⁡ 𝑝(x_t) \tag{141} \\
&= \frac{ 1}{\sqrt{α_t}}x_t+ \frac{1-\alpha_t}{\sqrt{α_t}}∇ \log⁡ 𝑝(x_t) \tag{142} \\
\end{align}
$$
因此，我们可以设置近视去噪均值 $\mu_\theta(x_t,t)$ 为：
$$
\mu_\theta(x_t,t) = \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}s_\theta(x_t,t) \tag{143}
$$
（译者言：请对照公式（125），再对照公式（126-130））相应的优化问题可以变为：
$$
\begin{align}
&~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q({{x}}_{t-1}|{{x}}_t,{{x}}_0)\Vert p_{{\theta}}({{x}}_{t-1}|{{x}}_t))\\
&=\arg\min_{{{\theta}}} D_{\text{KL}}(\mathcal{N} ({{x}}_{t-1}; μ_q, Σ_q(t)) \Vert \mathcal{N} ({{x}}_{t-1}; μ_{{\theta}}, Σ_q(t))) \tag{144} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1}{\sqrt{\alpha_t}}x_t + \frac{1-{\alpha}_t}{\sqrt{\alpha_t}}s_\theta(x_t,t) − \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{\alpha_t}}∇ \log⁡ 𝑝(x_t)\Big\Vert_2^2 \right] \tag{145} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert  \frac{1-{\alpha}_t}{\sqrt{\alpha_t}}s_\theta(x_t,t) - \frac{1-{\alpha}_t}{\sqrt{\alpha_t}}∇ \log⁡ 𝑝(x_t)\Big\Vert_2^2 \right] \tag{146} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert  \frac{1-{\alpha}_t}{\sqrt{\alpha_t}}(s_\theta(x_t,t) - ∇ \log⁡ 𝑝(x_t))\Big\Vert_2^2 \right] \tag{147} \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \frac{(1-{\alpha}_t)^2}{\alpha_t} \left[\Vert s_\theta(x_t,t) - ∇ \log⁡ 𝑝(x_t)\Vert_2^2 \right] \tag{148} \\
\end{align}
$$
这里，$s_θ(x_t, t)$ 可以是一个神经网络，用来学习预测分数函数（score function） $∇_{x_t} \log  p(x_t)$。对于任意的 $t$ 时间步的噪声，它用来预测针对 $x_t$ 的梯度。（译者言： $∇_{x_t} \log  p(x_t)$ 就是分数函数， 其性质后面会详细阐述）
敏锐的读者会注意到，分数函数 $∇ \log⁡ p(x_t)$ 在形式上与源噪声 $𝜖_0$ 非常相似。将Tweedie公式（公式133）与重参数化技巧（公式115）结合起来，可以明确地展示这一点：
$$
\begin{align}
x_0 = \frac{x_t+(1-\bar{\alpha}_t)∇ \log⁡ 𝑝(x_t)} {\sqrt{\bar{α}_t}} &= \frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}} \tag{149} \\
\therefore (1-\bar{\alpha}_t)∇ \log⁡ 𝑝(x_t) &= -\sqrt{1-\bar{\alpha}_t}\epsilon_0 \tag{150} \\
∇ \log⁡ 𝑝(x_t) &= - \frac{1}{\sqrt{1-\bar{\alpha}_t}}\epsilon_0 \tag{151} \\
\end{align}
$$
事实证明，这两个术语存在一个随时间变化而缩放的常数差！分数函数衡量了在数据空间中如何移动以最大化对数概率；直观地说，相对于正向的噪声被添加到原始图像的操作，反方向"去噪声"将是提高后续对数概率的最佳更新。我们用数学证明证实了这种直觉：学习模拟分数函数等价于模拟源噪声的相反数（差一个缩放因子）。因此，我们得出了三个等效的优化VDM的目标：学习神经网络预测原始图像 $𝑥_0$；学习神经网络预测源噪声 $𝜖_0$；学习一定噪声水平下的图像分数函数 $∇ \log⁡ p(x_t)$。通过随机采样时间步长 $𝑡$ 并使预测结果与基准真值目标的范数最小化，可以对VDM进行可扩展的训练。