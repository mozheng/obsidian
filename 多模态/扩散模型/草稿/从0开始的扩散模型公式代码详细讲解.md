
Denoising Diffusion Probabilistic Models  
论文：https://arxiv.org/abs/2006.11239  
代码：https://github.com/lucidrains/denoising-diffusion-pytorch  
```text
注意：同为图像生成，本章节不需要知道GAN或VAE的前置基础知识。
```
## 1. 背景介绍

扩散模型算法是一种受到热力学中非平衡热力学分支启发的算法，其思想来源是扩散过程，通过神经网络学习从纯噪声数据逐渐对数据进行去噪的过程，从单个图像样来看这个过程，扩散过程q就是不断往图像上加噪声直到图像变成一个纯噪声，扩散过程从 到最后的 就是一个马尔可夫链，表示状态空间中经过从一个状态到另一个状态的转换的随机过程。逆扩散过程p就是从纯噪声生成一张图像的过程。

## 2. 理论推理
### 2.1 变量声明
![](1.14.jpg)
1. $x_0$ 为原始图像， $x_t$ 为加t步噪声后的图像，噪声加到最后（第T步）为 $x_T$ 
2. 图像加噪声为 $q(x_t|x_{t-1})$ 操作，意为从 $x_{t-1}$ 加噪声成 $x_t$ ；图像降噪为 $p_\theta(x_{t-1}|x_t)$ 操作，意为从 $x_t$ 降噪声成 $x_{t-1}$ 
3. 每一步加噪声（或去噪声）都有参数对 $\alpha_t,\beta_t$ ，其中有 $0<\beta_t<<\alpha_t<1$ ，并且 $\alpha_t+\beta_t=1$

### 2.2 前向过程-混入噪声
1. 从原图 $x_0$ 开始一点一点加噪声
$$
\begin{align} 
x_1 &= \sqrt{\alpha_1}x_0+\sqrt{1-\alpha_1}Z_1 \\
x_2 &= \sqrt{\alpha_2}x_1+\sqrt{1-\alpha_2}Z_2 \\
&=\sqrt{\alpha_2 \alpha_1}x_0+\sqrt{\alpha_2(1-\alpha_1)}Z_1+\sqrt{1-\alpha_2}Z_2
\end{align}
$$
2. 因为噪声是基于标准正态分布随机采样的，后面两个噪声 $Z$ 可以合并到一起（即两个正态分布相加）。方法如下
$$
\begin{align} 
\sqrt{\alpha_2(1-\alpha_1)}Z_1 & \sim \mathcal{N}(0,\sqrt{\alpha_2-\alpha_2 \alpha_1}) \\
\sqrt{1-\alpha_2}Z_2 & \sim \mathcal{N}(0,\sqrt{1-\alpha_2 }) \\
\sqrt{\alpha_2(1-\alpha_1)}Z_1+\sqrt{1-\alpha_2}Z_2 & \sim \mathcal{N}(0,\sqrt{1-\alpha_2 \alpha_1})  \\
\end{align}
$$
可知 $x_2=\sqrt{\alpha_2 \alpha_1}x_0+\sqrt{1-\alpha_2 \alpha_1}Z$ ，这里的 $Z$ 没有下标，因为已经与 $Z_1$ 含义不同了，但还保持正态分布的特性。最终递归可得
$$
x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}Z , \bar{\alpha}_t=\Pi_{s=0}^{t}\alpha_s
$$
这里的 $\bar{\alpha_t}$ 就是前面 $\alpha$ 序列连续累乘的表示记法，与我们传统的平均数标识记法无关。用条件概率的写法就是
$$ q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})$$
注意，这里括号内的记法多了个 $x_t;$ ，代表这是 $x_t$ 的分布。其实本没有必要这么写，唯一的目的是让大家注意这是基于谁的分布。这一段对应的python的代码也很直接。其中 (sqrt_alphas_cumprod, t) 就是 $\sqrt{\bar{\alpha}_t}$ ，(sqrt_one_minus_alphas_cumprod, t) 就是 $\sqrt{1-\bar{\alpha}_t}$  
```python
def q_sample(self, x_start, t, noise=None):
	noise = default(noise, lambda: torch.randn_like(x_start))
	return (
		extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
		extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
	)
```

### 2.3 后向过程
反向过程都是基于 $q(x_{t − 1}∣x_t, x_0)$ 推理的。总体思想是，在知道原始图像 $x_0$ 、噪声 $x_t$ 的两个条件下给噪声 $x_t$ 降噪，得到  $x_{t − 1}$ 的过程。这时，许多人会有两个疑问点。

>**疑问点1：你不就是要一步一步求原始图像 $x_0$ 吗？你这里将原始图像 $x_0$ 当成条件是什么意思？**
> 对！因为单纯思考 $q ( x_{t − 1} ∣ x_t)$ 没有任何条件是肯定推不出来的，但是 $q(x_{t−1}∣x_0)$ 是可以的 。我这里借 $x_0$ 推理我的条件概率。而且由于上文推理出 $x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha_t}}Z$ 这一公式，可得 $x_0=\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_t)$ 。（注意：此时的 $\epsilon_t$ 与原始声明变量中的 $Z_t$ 存在代表上的不一致，他是正态重定义后的标识；但是他们是随机噪声，两者本质是一致的。）又因为 $x_0$ 也可以用 $x_t$ 进行表示，所以在把噪声参数当成常量时 ，$q ( x_{t − 1} ∣ x_t, x_0 )$ 与 $q ( x_{t − 1} ∣ x_t)$ 是相等。

> **疑问点2：后向过程不是说好了用  $p_\theta(x_{t-1}|x_t)$ 表示吗？你怎么还用 q？**
> 对！这里仅仅表示简单条件概率。单看在 $x_0$ 的条件下推理 $x_{t-1}$ ，这就是前向过程。我们可以把这一项当做反向过程 $p_\theta(x_{t-1}|x_t)$ 的 groundtruth 真实标注。
> 这里我们要引出本章的核心思想：**用 $q(x_{t − 1}∣x_t, x_0)$ 来指导反向去噪过程 $p_\theta(x_{t-1}|x_t)$  。**

接下来就是推理过程：
$$
\begin{align}
q({x}_{t-1} \vert {x}_t, {x}_0) 
&= q({x}_t \vert {x}_{t-1}, {x}_0) \frac{ q({x}_{t-1} \vert {x}_0) }{ q({x}_t \vert {x}_0) } \\
&= \frac{\sqrt{1-\bar{\alpha}_t}}{ \sqrt{2\pi}\sqrt{\beta_t}\sqrt{1-\bar{\alpha}_{t-1}}} \cdot e^ { (-\frac{1}{2} (\frac{({x}_t - \sqrt{\alpha_t} {x}_{t-1})^2}{\beta_t} + \frac{({x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} {x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{({x}_t - \sqrt{\bar{\alpha}_t} {x}_0)^2}{1-\bar{\alpha}_t} ) )}
\end{align}
$$
第一个等号是贝叶斯公式我知道，第二个等号是怎么回事？
其实这里都是高斯分布 $f(x)=\frac{1}{σ \sqrt{2π}} \cdot e^{\frac{-(x - μ)^2} {2σ^2}}$ ，相乘是指数相加，相除是指数相减。根据上一步的前向公式我们知道 $q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})$  与 $x_t = \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}Z_t$ ，因此我们可以推出以下：
$$
\begin{align}
q({x}_{t} \vert {x}_{t-1}, {x}_0)  &= \mathcal{N}(x_{t};\sqrt{\alpha_{t}}x_{t-1}, (1-{\alpha}_{t})\mathbf{I}) \\
q(x_{t-1}|x_0) & = \mathcal{N}(x_{t-1};\sqrt{\bar{\alpha}_{t-1}}x_0, (1-\bar{\alpha}_{t-1})\mathbf{I}) \\
q(x_t|x_0) & = \mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})
\end{align}
$$
前面设定了 $\alpha_t+\beta_t=1$ ，因此这里 $q({x}_{t} \vert {x}_{t-1}, {x}_0)= N(x_{t};\sqrt{\alpha_{t}}x_{t-1}, {\beta}_{t}\mathbf{I})$ ，继续推理得到以下的结果：
$$
\begin{align}
q({x}_{t-1} \vert {x}_t, {x}_0) 
&= q({x}_t \vert {x}_{t-1}, {x}_0) \frac{ q({x}_{t-1} \vert {x}_0) }{ q({x}_t \vert {x}_0) } \\
&= \frac{\sqrt{1-\bar{\alpha}_t}}{\sqrt{2\pi}\sqrt{\beta_t}\sqrt{1-\bar{\alpha}_{t-1}}} \cdot e^ {(-\frac{1}{2} (\frac{({x}_t - \sqrt{\alpha_t} {x}_{t-1})^2}{\beta_t} + \frac{({x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} {x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{({x}_t - \sqrt{\bar{\alpha}_t} {x}_0)^2}{1-\bar{\alpha}_t} ) ) }\\
&= C(\alpha,\beta,t)\cdot e ^ {-\frac{1}{2} (\frac{{x}_t^2 - 2\sqrt{\alpha_t} {x}_t {{x}_{t-1}} {+ \alpha_t} {{x}_{t-1}^2} }{\beta_t} + \frac{ {{x}_{t-1}^2} {- 2 \sqrt{\bar{\alpha}_{t-1}} {x}_0} {{x}_{t-1}} {+ \bar{\alpha}_{t-1} {x}_0^2}  }{1-\bar{\alpha}_{t-1}} - \frac{({x}_t - \sqrt{\bar{\alpha}_t} {x}_0)^2}{1-\bar{\alpha}_t} ) } \\
&= C(\alpha,\beta,t)\cdot e^{-\frac{1}{2} ( {(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}})} {x}_{t-1}^2 - {(\frac{2\sqrt{\alpha_t}}{\beta_t} {x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} {x}_0)} {x}_{t-1} + C({x}_t, {x}_0) ) )}
\end{align}
$$
最后一步是基于 $x_{t-1}$ 的二次方程的配方，因为我们算的就是  $x_{t-1}$ 分布嘛！开头项 $C(\alpha,\beta,t)$ 与最后项 $C(x_t,x_0)$  不是基于 $x_{t-1}$ 的函数可以这里将其分出来。这么做的目的其实是将本应是正态分布的 $q({x}_{t-1} \vert {x}_t, {x}_0)$ 化为正态分布格式，方便我们获取其均值与方差。又因为正态分布的 $(\sigma, \mu)$ 是基于二次方程配方结果。
$$
\begin{align}
\tilde{\sigma}_t 
&= 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) 
= 1/(\frac{\alpha_t - \bar{\alpha}_t + \beta_t}{\beta_t(1 - \bar{\alpha}_{t-1})})
= {\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
\tilde{\boldsymbol{\mu}}_t ({x}_t, {x}_0)
&= (\frac{\sqrt{\alpha_t}}{\beta_t} {x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} {x}_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) \\
&= (\frac{\sqrt{\alpha_t}}{\beta_t} {x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} {x}_0) {\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
&= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} {x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} {x}_0\\
\end{align}
$$
又因为我们是借 $q ( x_{t − 1} ∣ x_t)$ 算 $q ( x_{t − 1} ∣ x_t, x_0 )$ ，所以要通过 $x_0=\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t-\sqrt{1-\bar{\alpha}_t} \cdot \epsilon_t)$ 消去 $x_0$ 项。带入可得 
$$
\tilde{\boldsymbol{\mu}}_t ({x}_t, {x}_0) =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_t)
$$
最终总结可得：
$$
q({x}_{t-1} \vert {x}_t) = \mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_t,\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t)
$$

再强调一下，本章的核心思想：**用 $q(x_{t − 1}∣x_t, x_0)$ 来指导反向去噪过程 $p_\theta(x_{t-1}|x_t)$ 。**
$q(x_{t − 1}∣x_t, x_0)$ 的分布已经推理完成，我们会用它来仿造去噪过程 $p_\theta(x_{t-1}|x_t)$ 。但是不允许有 $x_0$ 、$\epsilon_t$ 出现。原因是去噪过程 $p_\theta(x_{t-1}|x_t)$ 是从噪声出发，不会出现原始图片 $x_0$ 这个元素，也不会出现确定的生成 $x_t$ 的噪声组 $\epsilon_t$。这种要求对方差 $\tilde{\sigma}_t$ 没有限制，但对均值 $\tilde{\boldsymbol{\mu}}_t ({x}_t, {x}_0)$ 就显得难办。我们接下来就要推理均值的拟合。从公式中我们也有一个大致的方向，假如将 $\epsilon_t$ 变成有参数的需要神经网络 $\theta$ 训练的元件 $\epsilon_\theta(x_t,t)$ ，问题也会解决。这种直觉指引我们下一步推理。我们重新从优化过程开始进行这种直觉的证明。
![](1.2.4-2.png)

### 2.4 优化过程
优化过程就是损失函数的计算，该推理有很多种方法，但大体一样。这里我选择一个我喜欢的方法。这是基于KL散度非负的特性做的，如下：
$$
 \begin{align} 
-\log p_\theta(x_0)&\leq-\log p_\theta(x_0)+D_{KL}(q(x_{1:T}|x_0)||p_\theta(x_{1:T}|x_0))\\ &=-\log p_\theta(x_0)+\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})/p_\theta(x_0)}\right];\text{where}\quad p_\theta(x_{1:T}|x_0)=\frac{p_\theta(x_{0:T})}{p_\theta(x_0)}\\
&=-\log p_\theta(x_0)+\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}+\underbrace{\log p_\theta(x_0)}_{与q无关，可拉出来}\right]\\ &=\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right]
 \end{align}
$$
这里正式使用了带参数 $\theta$ 的后向去噪 $p_\theta(x_{1:T}|x_0)$ 函数。上式左右两边取期望，并利用到重积分中的Fubini定理可得
$$\small\mathcal{L}_{VLB}=\underbrace{\mathbb{E}_{q(x_0)}\left(\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right]\right)=\mathbb{E}_{q(x_{0:T})}\left[\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right]}_{Fubini定理}\geq\mathbb{E}_{q(x_0)}[-\log p_\theta(x_0)]$$
> **说明**：Fubini提出：在一定可积的条件下，不仅能够用逐次积分计算双重积分，而且交换逐次积分的顺序时，积分结果不变。这个可积的条件在Fubini那里比较苛刻，但我们不用担心，因为这里的期望函数都比较简单。有兴趣的可以找资料详细研究，这里不做陈述。（就是懒）

这里，我们最小化左边的 $\small\mathcal{L}_{VLB}$ ，即可最小化 $p_\theta(x_0)$ 的信息熵的最大上界，从而最小化信息熵。下面过程很复杂知道即可，进一步推导VLB，得到组合的KL散度和熵。我们还可以将结果拆开写成右边这种格式
$$
\begin{aligned}
\mathcal{L}_\text{VLB} 
&= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big]\\
&= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\
&= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]
\end{aligned}
$$
看最后的公式推理，可以将结果简化为下面这种形式
$$
\begin{align}
 &\mathcal{L}_{VLB}=\mathbb{E}_{q}(L_T+L_{T-1}+...+L_0) \\ 
&L_T=D_{KL}(q(x_T|x_0)||p_\theta(x_T)) \\
&L_t=D_{KL}(q(x_t|x_{t+1},x_0)||p_\theta(x_t|x_{t+1}));\qquad 1\leq t \leq T-1 \\
&L_0=-\log p_\theta(x_0|x_1)
\end{align}
$$
这里的 $L_T,L_0$ 都是固定的，没有可优化价值我们关注中间的 $L_t$ ，它本质是下面两个正态分布求KL散度
$$
\begin{align}
q(x_{t-1}|x_t, x_0)=N(x_{t};\tilde{\mu}(x_t,x_0),\Sigma_t)&= \mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_t,t)),\Sigma)  \\
p_\theta(x_{t-1}|x_{t})=N(x_{t-1};\mu_\theta(x_t,t),\Sigma_t)&=\mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)),\Sigma)
\end{align}
$$
其中  $\Sigma_t= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t$ ，因为不包含目标 $x$ 与噪声 $\epsilon$ ，这里不展开说。根据多元高斯分布求KL散度的公式如下：
$$
\begin{align} 
L_{t-1}&=\mathbb{E}_{x_0,\epsilon_t}\left[\frac{1}{2||\Sigma(x_t,t)||_2^2}||\tilde{\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)||^2\right] \\
&=\mathbb{E}_{x_0,\epsilon_t}\left[\frac{1}{2||\Sigma(x_t,t)||_2^2}||\frac{1}{\sqrt{a_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{a}_t}}\epsilon_t)-\frac{1}{\sqrt{a_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{a}_t}}\epsilon_\theta(x_t,t))||^2\right] \\ 
&=\mathbb{E}_{x_0,\epsilon_t}\left[\frac{\beta_t^2}{2\alpha_t(1-\bar{\alpha}_t)||\Sigma(x_t,t)||_2^2}||\epsilon_t-\epsilon_\theta(x_t,t)||^2\right] \\ 
&=\mathbb{E}_{x_0,\epsilon_t}\left[\frac{\beta_t^2}{2\alpha_t(1-\bar{\alpha}_t)||\Sigma(x_t,t)||_2^2}||\epsilon_t-\epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t,t)||^2\right]
\end{align}
$$
此时我们发现只要通过拉进 $\epsilon_t$ 与 $\epsilon_\theta(x_t,t)$ 的距离的方式就可以训练参数 $\theta$。所以，我们利用噪声间MSE Loss 即可完成优化损失函数的设计：
$$ \mathcal{Loss} =  ||\epsilon_t-\epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t,t)||^2 
$$

## 3. 理论实现
### 3.1 训练过程

| 训练过程伪代码                                                                                                                                                  |
| -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1: repeat                                                                                                                                                |
| 2:    $x_0 \sim q(x_0),t\sim \text{Uniform}(\{1,2,...,T\}),\epsilon \sim \mathcal{N}(0,I)$                                                               |
| 3:    使用梯度下降逐步优化 $\nabla_\theta \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ |
| 4: until 收敛                                                                                                                                              |
表1.1 训练过程伪代码
上表1.1为原论文的训练过程，该过程比较简单：
1.  循环直到收敛
	1. 从数据集中选取 $x_0$ ，这就是原始图片；随机选取时间戳 t，它代表扩散模型需要扩散的轮数；生成t个高斯噪声，每个都是 $\epsilon_t\in\mathcal{N}(0, \mathbf{I})$
	2. 调用模型 $ϵ_θ$（这里是UNet网络）预估 $\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)$
	3. 计算噪声之间的 MSE Loss: $\mathcal{Loss} =  \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ 并梯度下降优化UNet网络。
对应python 训练代码如下：
```python
class GaussianDiffusionTrainer(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unet网络
        self.T = T

        self.register_buffer(
            'betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        self.register_buffer(
            'sqrt_alphas_bar', torch.sqrt(alphas_bar))
        self.register_buffer(
            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))

    def forward(self, x_0):
        """
        Algorithm 1.
        """
        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)
        noise = torch.randn_like(x_0)
        x_t = (
            extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 +
            extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise)
        loss = F.mse_loss(self.model(x_t, t), noise, reduction='none')
        return loss
```
### 3.2 推理过程

此时，在我们再次强调我们在2.3提到的核心目标：
用未知 $x_0,z_t$ 原始值的**近似去噪分布** $p_θ(x_{t−1}|x_t)$ 来近似已知原始图片 $x_0$ 的**真值去噪分布** $q(x_{t−1}|x_t,x_0)$ 
那么 $p_θ(x_{t−1}|x_t)$ 可以尽可能的仿作：
$$
p_\theta({x}_{t-1} \vert {x}_t) = \mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)),\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}})
$$
我们知道 $x_{t-1} \sim p_\theta(x_{t-1}|x_t)$ ，按照初中的规则，我们可以将其化为正态分布的格式，步骤如下：
$$
\begin{align}
& \frac{x_{t-1} - \mu}{\sigma} \sim \mathcal{N}(0,I)=z \\
& x_{t-1} = \mu + \sigma z \\
& x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z \tag{1.154}
\end{align}
$$
在DDPM中，用符号 $z$ 代替标准正态分布噪声，虽然本质与 $\epsilon$ 相同，但实际含义不一样。伪代码如表1.2所示：

| 前向推理采样算法伪代码                                                                                                                      |
| -------------------------------------------------------------------------------------------------------------------------------- |
| 1: $x_T \sim \mathcal{N}(0,I)$                                                                                                   |
| 2: for $t=T,...,1$ do:                                                                                                           |
| 3:     $z \sim \mathcal{N}(0,I)$ if $t>1$ ， else $z=0$                                                                           |
| 4:     $x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1- \alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \sigma_t z$ |
| 5: end for                                                                                                                       |
| 6: return $x_0$                                                                                                                  |
表1.2 采样算法伪代码

此时已经训练出来了 $\epsilon_θ$ （这里是UNet网络），所以在下面的推理过程中 $ϵ_θ(x_t,t)$ 是已知的。假设我用推理的过程中扩散T步，那么从T步开始逆向回推，每一步有如下操作：
1. 初始化最终的扩散状态 $x_T$ 为纯高斯噪声，从这个状态开始进行反推。
2. 从 $t=T$ 步开始，每步减一，直到 $t=1$ ：
	1. 如果是最后一轮循环 $t=1$ ，噪声 $z = 0$ ；如果 $t > 1$ 时，即可取随机噪声 $z\in\mathcal{N}(0, \mathbf{I})$ 。
	2. 推论 $x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z$
3. 最后一步返回 $x_0$
对应的python代码如下，同样很清晰：
```python
class GaussianDiffusionSampler(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unet
        self.T = T

        self.register_buffer('betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)
        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]

        self.register_buffer('coeff1', torch.sqrt(1. / alphas))
        self.register_buffer('coeff2', self.coeff1 * (1. - alphas) / torch.sqrt(1. - alphas_bar))

        self.register_buffer('posterior_var', self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))

    def predict_xt_prev_mean_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            extract(self.coeff1, t, x_t.shape) * x_t -
            extract(self.coeff2, t, x_t.shape) * eps
        )

    def p_mean_variance(self, x_t, t):
        # below: only log_variance is used in the KL computations
        var = torch.cat([self.posterior_var[1:2], self.betas[1:]])
        var = extract(var, t, x_t.shape)

        eps = self.model(x_t, t)
        xt_prev_mean = self.predict_xt_prev_mean_from_eps(x_t, t, eps=eps)

        return xt_prev_mean, var

    def forward(self, x_T):
        """
        Algorithm 2.
        """
        x_t = x_T
        for time_step in reversed(range(self.T)):
            print(time_step)
            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step
            mean, var= self.p_mean_variance(x_t=x_t, t=t)
            # no noise when t == 0
            if time_step > 0:
                noise = torch.randn_like(x_t)
            else:
                noise = 0
            x_t = mean + torch.sqrt(var) * noise # μ+σ*z
            assert torch.isnan(x_t).int().sum() == 0, "nan in tensor."
        x_0 = x_t
        return torch.clip(x_0, -1, 1)
```

