在生成扩散技术蓬勃发展的浪潮中，流匹配（Flow Matching，FM）生成模型凭借其独特优势脱颖而出。该模型基于连续标准化流（Continuous Normalizing Flows，CNFs）构建，为生成模型的训练开辟了新的路径，能够使模型有效学习复杂的数据分布，进而生成高质量样本。当前取得卓越成效的生成模型 FLUX 与 Stable Diffusion 3，均是基于流匹配理论发展而来的扩散模型。接下来将深入剖析流匹配生成模型的核心机制，鉴于其作为新型扩散模拟的特性，本文将结合示意图进行整体阐述，具体细节详见本文后续内容。
![](../images/流匹配.jpg)
本文的主要内容源自 Yaron Lipman 等人撰写的《FLOW MATCHING FOR GENERATIVE MODELING》一文，后续将简称为 “流匹配论文”。鉴于流模型内容丰富，我们将分多个章节进行讲解。本节侧重于理论层面，暂不涉及具体实现。核心要点在于帮助大家理解最优传输（OT）理论的提出过程及其内涵。

### 2.4.1 流匹配基础公式
**流的核心思想是将一个分布使用函数族 $f_1,f_2,...,f_k,...$ 转化为另一个分布。**
本小节的编排逻辑源于传统流模型理论体系。早期经典流模型著作（如《Normalizing Flows》）通常以 RealNVP 架构为核心展开，对 "变量替换方程" 的数学推导着墨甚多。若仅需掌握 "流匹配基础"，重点理解以下两点即可：其一，变量替换方程是流模型的核心数学工具；其二，流模型本质上是由一系列连续可逆变换构成的理论体系。这两项核心结论将在后续章节的流场匹配分析中发挥关键作用。
#### 2.4.1.1 变量替换方程
流模型通过一系列由变量替换方程支撑的可逆变换，来描述这个分布转换函数 $f$ 。变量替换方程主要基于雅可比变换（也叫变量替换公式）以及概率密度函数的变换规则推导得出。 
> [!雅可比矩阵]
> 雅可比矩阵是函数对**向量导数**的扩展。如果 $\mathbf{z}=f(\mathbf{x})$ ，雅可比矩阵 $J_f$ 定义为
>$$J_f=\frac{\partial \mathbf{z}}{\partial \mathbf{x}}=
\begin{bmatrix}\frac{\partial z_1}{\partial x_1} & \frac{\partial z_1}{\partial x_2}&\cdots&\frac{\partial z_1}{\partial x_d} \\
\frac{\partial z_2}{\partial x_1} & \frac{\partial z_2}{\partial x_2}&\cdots&\frac{\partial z_2}{\partial x_d} \\
\vdots&\vdots&\ddots&\vdots \\
\frac{\partial z_d}{\partial x_1} & \frac{\partial z_d}{\partial x_2}&\cdots&\frac{\partial z_d}{\partial x_d}
\end{bmatrix}$$
> 雅可比矩阵是一个在数学、物理、工程等多个领域都具有重要意义的概念，在多元积分中，雅可比矩阵的行列式 $|J_f(\mathbf{x})|$ 起到了关键作用。它描述了从原变量 $\mathbf{x}$ 到新变量 $\mathbf{z}$ 的变换过程中，体积微元的变化比例。具体来说，积分 
> $$\int_D g(\mathbf{z})\mathrm{d}\mathbf{z}$$ 
> 在  $\mathbf{z}=f(\mathbf{x})$ 变量替换后，可转化为 
> $$\int_{D'} g(f(\mathbf{x})) |J_f(\mathbf{x})|\mathrm{d}\mathbf{x}$$ 
> 其中 $D$ 和 $D'$ 分别是原变量和新变量下的积分区域。这种积分变换计算，例如从直角坐标到极坐标、柱坐标或球坐标的转换中经常用到。同样的，我们在大学高等数学课程中，也有如下针对于一元函数的换元转换。
> $$\int_D g(z)\mathrm{d}x =\int_{D'} g(f(x))\mathrm{d}f(x)=\int_{D'} g(f(x)) f'(x)\mathrm{d}x$$

我们先给出两个变量替换说明
- **变量设定说明**：$\mathbf{x}$ 是一个 $d$ 维随机变量，其概率密度函数为 $p(\mathbf{x})$。我们通过一系列可逆变换 $f$ 将 $\mathbf{x}$ 变换为另一个 $d$ 维随机变量 $\mathbf{z}$ ，即 $\mathbf{z}=f(\mathbf{x})$，并且 $f$ 是一个一一映射（可逆）且可微的函数。
- **一一映射概率等价说明**：对于一个微小区域 $\mathrm{d}\mathbf{x}$ ，$\mathbf{x}$ 落在这个区域的概率为 $p_\mathbf{x}(\mathbf{x})\mathrm{d}\mathbf{x}$（这里 $\mathrm{d}\mathbf{x}=\mathrm{d}x_1\mathrm{d}x_2\cdot\cdot\cdot\mathrm{d}x_d$）；经过变换后，$z$ 落在对应区域 $\mathrm{d}z$ 的概率为 $p_\mathbf{z}(\mathbf{z})\mathrm{d}\mathbf{z}$ （同样 $\mathrm{d}\mathbf{z}=\mathrm{d}z_1\mathrm{d}z_2\cdot\cdot\cdot\mathrm{d}z_d$）。由于变换是一一映射的，这两个概率应该相等，即 $p_\mathbf{x}(\mathbf{x})\mathrm{d}\mathbf{x}=p_\mathbf{z}(\mathbf{z})\mathrm{d}\mathbf{z}$。
因此我们把 $\mathrm{d}\mathbf{z}=|\det(J_f(\mathbf{x}))|\mathrm{d}\mathbf{x}$ 代入 $p_\mathbf{x}(\mathbf{x})\mathrm{d}\mathbf{x}=p_\mathbf{z}(\mathbf{z})\mathrm{d}\mathbf{z}$ 可得：
$$\begin{align}
p_\mathbf{x}(\mathbf{x})\mathrm{d}\mathbf{x} &=p_\mathbf{z}(\mathbf{z})\mathrm{d}\mathbf{z} \tag{}\\
&= p_\mathbf{z}(\mathbf{z})|J_f(\mathbf{x})|\mathrm{d}\mathbf{x}  \tag{}\\
\rightarrow p_\mathbf{x}(\mathbf{x}) &=p_\mathbf{z}(f(\mathbf{x}))|J_f(\mathbf{x})| \tag{2.4.1}
\end{align}$$
我们在最后一步消掉了两边的 $\mathrm{d}\mathbf{x}$ 得到公式（2.4.1）。这就是我们在流模型中核心使用的**变量替换方程**。
> [!warning]
>  在流匹配论文中，使用 $x=f(z)$ 从噪声到图像的生成逻辑推理公式，那么有
>  $$p_\mathbf{x}(\mathbf{x}) =p_\mathbf{z}(f^{-1}(\mathbf{x}))|J_{f^{-1}}(\mathbf{x})|$$ 
>  再根据反函数定理 $|J_{f^{-1}}(\mathbf{x})|=|J_{f}(\mathbf{x})|^{-1}$  可得
>   $$p_\mathbf{x}(\mathbf{x}) =p_\mathbf{z}(f^{-1}(\mathbf{x}))|J_{f}(\mathbf{x})|^{-1}=p_\mathbf{z}(f^{-1}(\mathbf{x}))\det[\frac{\partial \mathbf{f}^{-1}}{\partial \mathbf{x}}(x)] \tag{2.4.2}$$ 
>   如果在其他地方看到这两种形式，请不要疑虑，本质相同。

#### 2.4.1.2 连续标准化流

**连续标准化流** （Continuous Normalizing Flows, CNFs）表述如下：在 $d$ 维数据空间$\mathbb{R}^{d}$中，有概率密度路径 $p : [0, 1]×\mathbb{R}^{d}→\mathbb{R}_{>0}$ 和时间依赖向量场 $v : [0, 1]×\mathbb{R}^{d}→\mathbb{R}^{d}$ 。根据向量场 $v_{t}$ 可构建流 $\phi : [0, 1]×\mathbb{R}^{d}→\mathbb{R}^{d}$ ，两者关系为 $\frac{d}{dt}\phi_{t}(x)=v_{t}(\phi_{t}(x)),\phi_0(x)=x$ 。这里的向量场 $v_{t}$ 用神经网络$v_{t}(x;\theta)$ 建模。这里 $\phi_t$ 是CNF 。
通俗地讲的就是：现有一个取值范围编排0到1的时间序列 $t$，不同于之前扩散模型的时间 $t$ 为整数，这里的 $t$ 标准化到 $[0,1]$ 区间，本质上是为了更好地参与积分计算。因为有 $t$ ，所以有 $t$ 时间点的概率密度路径 $p_t$ ， $t$ 时间点的 $\phi_t$ （对应上文中的 $f^{-1}$），以及 $t$ 时间点的时间依赖向量场 $v_t$ 。我们常常使用参数 $\theta$ 代表需要建模的模型，又因为 $v_t,\phi_t$ 同源， 所以这里用 $v_{t}(x;\theta)$ 建模来表示 $\phi_t$ 。这里 $\phi_t$ 是CNF，连续的CNF集合形成CNFs。
我们可以将上面的向量场 $v_t$ 理解为 $\phi_t$ 的导数。但其实设计这个参数符号的人是想让你往“**速度**”的角度进行理解。我们可将简单噪声 $x_0$ 到生成图像的复杂分布 $x_1$ 看成一条t路径，这里称为“**条件概率路径**”。向量场 $v_t$ 就是在这条路径上的交通工具行驶的速度。那么连续标准化流的采样方法变成了小学数学中我们常用的“**速度-距离**”方程： $x_{t+\Delta t} = x_t + \Delta t v_t$ 。

这里，我用两种方法阐述“连续标准化流”。因为我们即要照顾到数学的严谨性，又需照顾到读者的理解。两种方法都很重要，因为通俗的部分是让大家懂我们在做什么，严谨的部分主要防止大家抬杠。所以我们看到数学公式时不要害怕，试着自己用土话或大白话翻译一下一大坨公式究竟要干什么。

> [!连续性方程]
> 上面连续性的概念来自**连续性方程**。它是描述流体的物理概念，如 $\rho_t(x)$ 满足连续性方程，则有：
$$\frac{\mathrm{\partial}}{\mathrm{\partial}t}\rho_t(x)= -div(u_t(x)\rho_t(x))$$
注意，这里的散度 $div$ 操作没有 $t$ 的偏导 ，在三维空间中有如下表示：
$$\text{div} \ u = \frac{\mathrm{\partial}u}{\mathrm{\partial}x}+\frac{\mathrm{\partial}u}{\mathrm{\partial}y} + \frac{\mathrm{\partial}u}{\mathrm{\partial}z}$$
>如果是多维空间散度，散度操作需要再在加几个偏导。我们粗浅地理解下这个公式。在流体物理学中，**流入=流出**，即可得 “**通过一个截面的流体质量变化量=通过这个截面的流体的流量 * 这个截面的密度**” 。因为散度是个向量，方向相反，所以前面有负号。有人说这种相等不是很正常的事吗？并不是，流淌中断，没有算完全部支流等不可避免的原因都不会使等式相等。我们这里是用计算机模拟自然，是可以应用到理论的结果。
>在基于 CNFs 的生成模型中，满足连续性方程是确保模型合理性和有效性的关键。它保证了所构建的概率路径 $p_t(x)$ 能够通过合适的向量场 $u_t(x)$ 进行合理的变换，从而实现从简单先验分布到复杂数据分布的映射。如果不满足连续性方程，那么概率分布的变换将不符合物理和概率的基本原理，模型就无法准确地对数据进行建模。

>[!注意]
>与之前的扩散模型不一样，这里的开始时间 $t=0$ 是简单噪声，归一化后的结束时间 $t=1$ 为生成图像后的时间。同时，为了让适配更通用说法，我们不将生成目标假定为图片，而是将 $t=0$ 的 $p_0$ 称为**简单正态分布**，你可以认为是  $p_0(x)=\mathcal{N}(0,\mathbf{I})$; $t=1$ 的 $p_1$ 称为**复杂的生成正态分布**。

根据流模型变量替换公式（2.4.2）我们可得 0-1时间段的某个时间点 $t$ 的概率密度路径 $p_t$ 可表示为
$$p_{t}=p_{0}(\phi_t^{-1})\det[\frac{\partial \mathbf{\phi_t^{-1}}}{\partial \mathbf{x}}(x)]$$
 $p_0$ 表示一种简单的初始分布，通常是标准正态分布。这里使用 $p$ 作为概率函数表示，其命名逻辑与上一章的逻辑一样，依然代表“从原始噪声数据推断到生成图片数据”的过程。流匹配论文中使用下角标 * 运算符，将公式简写为
$$p_{t}=p_{0}(\phi_t^{-1})\det[\frac{\partial \mathbf{\phi_t^{-1}}}{\partial \mathbf{x}}(x)]=[\phi_t]_* p_0 \tag{2.4.3}$$
公式（2.4.3）就是CNF的**前推公式**（push-forward equation）。
我们盘点一下我们现有的资料。训练数据样本 $q_{data}(x_1)$ （简称 $q(x_1)$）无法访问密度函数本身。我们要做的是构建一套可逆概率路径 $p_0,...,p_t,...,p_1$，使最后的 $p_1$ 分布不断逼近 $q$，与 $q$ 尽可能相似。具体怎样构建这样的合适概率路径，这就是**流匹配**（FM，CFM）的问题了。
### 2.4.2 流匹配（FM）原理 
#### 2.4.2.1 流匹配目标函数
虽然我们已经有个（2.4.3）公式了，但是其中的 $\phi_t$ （或者与其相关的 $v_t$ ）怎么求我们并不知道。
我们换种思维，选择基于速度 $v_t$ 建模。假设目标概率密度是 $p_{t}(x)$ ，其对应的向量场为 $u_{t}(x)$（向量场 $u_{t}(x)$ 可看做上面以 $\theta$ 为参数的速度模型 $v_t(x,\theta)$ 的groundtruth）。那么我们可以，通过这样的**流匹配（FM）目标函数**来训练模型 $v_t(x,\theta)$：
$$\mathcal{L}_{FM}(\theta)=\mathbb{E}_{t,p_{t}(x)}\left\| v_{t}(x,\theta)-u_{t}(x)\right\| ^{2}$$
其中 $\theta$ 是CNF向量场 $v_{t}$ 的可学习参数， $t \sim U[0, 1]$，$x \sim p_{t}(x)$  。直观理解，FM就是用神经网络 $v_{t}$ 去逼近向量场 $u_{t}$ ，当损失为0时，学习到的CNF模型就能生成 $p_{t}(x)$ 。理想很丰满，现实很闹心。向量场为 $u_{t}(x)$ 是什么我们并不知道。基于DDPM的经验，如果当前概率不知道，你加个条件不就完了吗？DDPM里面不知道 $q(x_{t−1}|x_t)$ ，所以往条件里面加个一个原始图像 $x_0$ ，形成求 $q(x_{t−1}|x_t,x_0)$ 的局面。流模型中我们想生成的复杂分布对象是 $x_1$ 。顺着DDPM的推导思路。我们自然想到可以求条件向量场 $u_{t}(x|x_{1})$ ，同配套的还有 $p_{t}(x|x_{1})$ 。因此接下来做的就是要探讨“**条件流匹配**（CFM）与当前**流匹配**（FM）有何关系了。
#### 2.4.2.2 流匹配与条件流匹配建立关系的前提
条件流匹配与流匹配的关系，主要来基于“条件向量场，条件概率路径”与“向量场，概率路径”的这组变量的关系。因为我们要用条件向量场 $u_t(x|x_1)$ 和条件概率路径 $p_t(x|x_1)$ **推理**向量场 $u_t(x)$ 和概率路径 $p_t(x)$ 。所以我们还得需要探索或设计一条规则，将条件概率和概率两边建立关系。

**思路：对于任意原始数据的复杂分布 $q(x_1)$，如果给定条件向量场 $u_t(x|x_1)$ 和生成条件概率路径 $p_t(x|x_1)$ ，即上式中的连续性公式 $\frac{\mathrm{d}}{\mathrm{d}t}p_t(x|x_1)= -\text{div}(u_t(x|x_1)p_t(x|x_1))$ 。那么我们可以设计条件，让向量场 $u_t(x)$ 和会生成这样概率路径 $p_t(x)$，满足连续性方程 。** 

但是，怎么设计可行的条件呢？我们的思路如下。根据条件全概率公式, 使用 $x_1$ 划分方程可得：
$$p_t(x)=\int p_t(x|x_1)q(x_1)\mathrm{d}x_1$$
如果 $p_t(x)$ 对 $t$ 求微分，还由于上文中只有 $p_t(x|x_1)$ 有 $t$，所以有
$$\begin{align}
\frac{\mathrm{d}}{\mathrm{d}t}p_t(x)&=\int (\frac{\mathrm{d}}{\mathrm{d}t}p_t(x|x_1))q(x_1)\mathrm{d}x_1 \tag{}\\
&=-\int [\text{div}(u_t(x|x_1)p_t(x|x_1))]q(x_1)\mathrm{d}x_1 \tag{}\\
&=-\text{div}\int u_t(x|x_1)p_t(x|x_1)q(x_1)\mathrm{d}x_1 \tag{2.4.4}
\end{align}$$
最后公式（2.4.4）的转换来自Leibinz积分法则，对调积分与导数。在这里，如果设定如下的 $u_t(x)$
$$u_t(x)=\int u_t(x|x_1)\frac{p_t(x|x_1)q(x_1)}{p_t(x)}\mathrm{d}x_1 \tag{2.4.5}$$就可以得到连续性方程
$$\frac{\mathrm{d}}{\mathrm{d}t}p_t(x)=-\text{div}(u_t(x)p_t(x))$$
其中，公式（2.4.5）就是我们设计的向量场 $u_t(x)$ 的公式。我们在这里，终于获得条件向量场与向量场的转换关系。下面我们会大胆深入条件向量场来解决当前的问题。

> 有人说，这不明显有问题吗？你自己设计个公式（2.4.5）搞循环论证可以吗？还真行，原因是向量场这东西不同液体有不同结果，我们又不是真的要找到这样的液体。
#### 2.4.2.3 条件流匹配优化等价于流匹配优化
为了可以继续计算，现在我们考虑构建条件概率路径 $p_{t}(x|x_{1})$ 和条件向量场 $u_{t}(x|x_{1})$ ，我们得到了条件匹配（CFM）目标函数
$$\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}\left\| v_{t}(x,\theta)-u_{t}(x|x_{1})\right\| ^{2}$$
这个目标函数有一个很振奋人心的点：FM和CFM目标函数对$\theta$的梯度相同。这届就意味着优化CFM目标函数等同于优化FM目标函数，我们直接训练CNF模型就可以了。
> [!流匹配目标函数=条件流匹配目标函数]
> 定理：**假设对于所有的 $x\in\mathbb{R}^{d}$ , $t\in[0,1]$ ，都有 $p_{t}(x)>0$，那么，在一个与 $\theta$ 无关的常数范围内，则 $\mathcal{L}_{FM}(\theta)=\mathcal{L}_{CFM}(\theta)$ ，即**
> $$\mathbb{E}_{t,p_{t}(x)}\left\| v_{t}(x,\theta)-u_{t}(x)\right\| ^{2}=\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}\left\| v_{t}(x,\theta)-u_{t}(x|x_{1})\right\| ^{2}$$  
> 我们拆开L2范式，可得
> $$\begin{align}
\left\| v_{t}(x,\theta)-u_{t}(x)\right\| ^{2} &=\left\| v_{t}(x,\theta)\right\| ^{2} -2\lt v_{t}(x,\theta),u_{t}(x)\gt + \left\|u_{t}(x)\right\| ^{2} \tag{} \\
\left\| v_{t}(x,\theta)-u_{t}(x|x_1)\right\| ^{2} &=\left\| v_{t}(x,\theta)\right\| ^{2} -2\lt v_{t}(x,\theta),u_{t}(x|x_1)\gt + \left\|u_{t}(x|x_1)\right\| ^{2} \tag{} \\
\end{align}$$
> 前面就说了 $u_{t}(x),u_{t}(x|x_1)$ 是 groundtruth，不参与期望运算，第三项相等。根据第一章的教科书不证明的期望定义可推理出第一项也相等，证明如下：
> $$\begin{align}
> \mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}\left\| v_{t}(x,\theta)\right\| ^{2}&=\int \left\| v_{t}(x,\theta)\right\| ^{2}p_{t}(x|x_{1})q(x_{1})\mathrm{d}x \tag{} \\
> &= \int \left\| v_{t}(x,\theta)\right\| ^{2}p_{t}(x)\mathrm{d}x=\mathbb{E}_{t,p_{t}(x)}\left\| v_{t}(x,\theta)\right\| ^{2} \tag{} 
> \end{align}$$
> 第二项也相等，证明如下：
> $$\begin{align}
> \mathbb{E}_{t,p_{t}(x)}\lt v_{t}(x,\theta),u_{t}(x)\gt&=\int \lt v_{t}(x,\theta),u_{t}(x) \gt p_{t}(x)\mathrm{d}x \tag{} \\
> &= \int \lt v_{t}(x,\theta),\int u_t(x|x_1)\frac{p_t(x|x_1)q(x_1)}{p_t(x)}\mathrm{d}x_1 \gt p_{t}(x)\mathrm{d}x \tag{} \\
> &= \int \lt v_{t}(x,\theta),\int u_t(x|x_1)p_t(x|x_1)q(x_1)\mathrm{d}x_1\gt\mathrm{d}x \tag{} \\
> &= \int \lt v_{t}(x,\theta),u_t(x|x_1)\gt p_t(x|x_1)q(x_1)\mathrm{d}x_1\mathrm{d}x \tag{} \\
> &=\mathbb{E}_{t,p_{t}(x|x_1),q(x_1)} \lt v_{t}(x,\theta),u_{t}(x|x_1)\gt \tag{} 
> \end{align}$$
> 三项皆等，$\mathcal{L}_{FM}(\theta)=\mathcal{L}_{CFM}(\theta)$ 成立

#### 2.4.2.4 条件流匹配模型最终构建
在经过前三节的详细铺垫后，我们对所涉及的流模型有了清晰的认识：该模型基于模拟物理学中流体力学的连续流方程构建。 接下来，我们对当前已有的条件进行梳理。模型从起始点的简单正态分布（即正态噪声）过渡到终止点的复杂分布（也就是生成结果），这一过程构成了一条概率路径。将每一步的节点记为$p_t(x)$，这些连续的$p_t(x)$满足连续性方程。虽然该连续方程所体现的逐步推进的特性与扩散模型的行为一致，但这部分内容我们将在后续讨论。由于起始点与终止点的状态是固定的，当我们试图构建这条概率路径时，可以以$\theta$为参数对速度向量（即向量场）$v_{t}(x,\theta)$进行建模预测，这便是我们目前的核心工作。此处，向量场的真实值为$u_{t}(x)$ 。 直接求解$p_t(x)$和$v_{t}(x)$存在较大困难，因此，我们采用计算条件概率$p_{t}(x|x_1)$的方法来确定所有路径。我们设定前面提及的条件概率路径为$p_{t}(x|x_{1})=\mathcal{N}(x|\mu_{t}(x_{1}),\sigma_{t}(x_{1})^{2}\mathbf{I})$，其中$\mu_{t}(x_{1})$为均值，$\sigma_{t}(x_{1})$为标准差。具体而言： 
- 当$t = 0$处于初始状态时，$\mu_{0}(x_{1}) = 0$，$\sigma_{0}(x_{1}) = 1$ ，因为此时$p_{0}(x|x_{1})=\mathcal{N}(x|0,\mathbf{I})$，呈现为一个简单的正态分布。 
- 同样地，当$t = 1$达到终止状态时，$\mu_{1}(x_{1}) = x_{1}$，$\sigma_{1}(x_{1})=\sigma_{min}$（取值足够小），目的是使$p_{1}(x|x_{1})$成为集中于$x_{1}$的正态分布。理论上，$\sigma_{1}(x_{1}) = 0$最为理想，但正态分布的方差不能为$0$，所以在此标记为足够小的$\sigma_{min}$ 。 
- 我们可以把路径$p_t(x|x_t)$看作是对$\psi_t(x) = \sigma_{t}(x_{1}) x+\mu_t(x_1),\mathcal{N}(x|0,\mathbf{I})$的采样。需要注意的是，$\psi_t(x)$并非函数，而是一个随机变量。

根据连续标准流的公式，可得向量场（也可以理解为速度）的结果 $\frac{d}{dt}\psi_{t}(x)=u_{t}(\psi_t(x)|x_1)$ 。下面对 $t$ 求导可得

$$\psi_t'(x) = \sigma_{t}'(x_{1}) x+\mu_t'(x_1)$$

逆向带入 $\psi_t(x) = \sigma_{t}(x_{1}) x+\mu_t(x_1)$ 得：$x=\frac{\psi_t(x)-\mu_t(x_1)}{\sigma_{t}(x_{1})}$ 
$$\psi_t'(x) = \sigma_{t}'(x_{1}) \frac{\psi_t(x)-\mu_t(x_1)}{\sigma_{t}(x_{1})}+\mu_t'(x_1)=u_{t}(\psi_t(x)|x_1)$$

再次强调一点 $\psi_t(x)$ 不是函数而是一个随机变量，它是条件概率路径 $p_t(x|x_t)$，是由 $\mathcal{N}(x|\mu_{t}(x_{1}),\sigma_{t}(x_{1})^{2}\mathbf{I})$ 采样得出，后面由 $x$ 代替。 基于以上的条件，我们就可以得到向量场为
$$u_{t}(x|x_{1})=\frac{\sigma_{t}'(x_{1})}{\sigma_{t}(x_{1})}(x-\mu_{t}(x_{1}))+\mu_{t}'(x_{1}) \tag{2.4.6}$$
那么条件流匹配目标函数可以写为如下形式：
$$\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}\left\| v_{t}(x,\theta)-[\frac{\sigma_{t}'(x_{1})}{\sigma_{t}(x_{1})}(x-\mu_{t}(x_{1}))+\mu_{t}'(x_{1})]\right\| ^{2} \tag{2.4.7}$$
请注意，公式（2.4.6）是建立在 $p_{t}(x|x_{1})=\mathcal{N}(x|\mu_{t}(x_{1}),\sigma_{t}(x_{1})^{2}\mathbf{I})$ 的基础上。概率路径是随机分布的。如果我们使用其他的方法建立概率路径呢？下面我们就说一下其他概率路径的流模型。

>[!注意]
>流匹配论文是用另一个公式，并用 $x_0$ 重参数化，但两者一致：
> $$\begin{align}
> \mathcal{L}_{CFM}(\theta)&=\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}\left\| v_{t}(\psi_t(x),\theta)-[\sigma_{t}'(x_{1})\psi_t(x)+\mu_{t}'(x_{1})]\right\| ^{2} \tag{} \\
> &=\mathbb{E}_{t,q(x_{1}),p_{t}(x_0)}\left\| v_{t}(\psi_t(x_0),\theta)-\psi_t'(x_0)]\right\| ^{2} \tag{}
> \end{align}$$

### 2.4.3 概率路径与最优传输 
与EDM论文一样，流匹配论文也在使用自己的方式统一扩散模型的解释。其关键的点在于概率路径 $p_{t}(x|x_{1})$ 。因为初始状态与终止状态是确定的，概率路径怎么走我们是可以指定的，如果你高兴甚至可以走“螺旋升天”的路径。那么这里边有两个路径，我们很熟悉：
- 方差爆炸（VE）路径 $p_{t}(x|x_1)=\mathcal{N}(x|x_{1},\sigma_{1 - t}^{2}\mathbf{I})$ 。
- 方差保持（VP）扩散路径 $p_{t}(x|x_{1})=\mathcal{N}(x|\alpha_{1 - t}x_{1},(1-\alpha_{1 - t}^{2})\mathbf{I})$ 。
但在这里，我们又不是要推理DDPM。我们当然更喜欢最优的流匹配概率路径，就是 “**最优传输条件向量场**”
#### 2.4.3.1 最优传输条件向量场
最优传输（Optimal Transport，OT）研究的是如何以最小的 “代价” 将一个概率分布转换为另一个概率分布。这里的 “代价” 基于某种距离度量，比如两个分布中元素之间的距离，在数学上可以认为是从一个概率分布到另一个概率分布的最优映射。
这里的最优传输OT是这样定义的：
概率路径依然采用 $p_{t}(x|x_{1})=\mathcal{N}(x|\mu_{t}(x_{1}),\sigma_{t}(x_{1})^{2}\mathbf{I})$ ，但是 $\mu_{t}(x)=tx_{1}$，$\sigma_{t}(x)=1-(1-\sigma_{min})t$ 。对应的条件流 $\psi_{t}(x)=(1-(1-\sigma_{min})t)x+tx_{1}$ ，可看成两个高斯分布间的最优传输位移映射 。我们根据公式（2.4.6）可以计算得到的条件向量场
$$u_{t}(x|x_{1})=\frac{x_{1}-(1-\sigma_{min})x}{1-(1-\sigma_{min})t} \tag{2.4.8}$$与其他扩散路径相比，OT路径粒子运动轨迹是直线，更易于用参数模型拟合，训练和采样效率更高。之前说过 $\sigma_{min}$ 在数学上理解可以为0，即
$$\psi_{t}(x)=(1-t)x+tx_{1}$$如果从初始分布采样 $X_0\sim\pi_0$ ，从终止分布采样 $X_1\sim\pi_1$，我们可以得到中间的分布采样 $X_t= tX_1+(1-t)X_0$ 。此时，最优传输OT的微分方程就是这样很简单的形状
$$\frac{\mathrm{d}}{\mathrm{d}t}x_t= X_1 -X_0 \tag{2.4.9}$$

讲到这里，我可以预测到读过上一章SDE的人都会哭。上一章DDPM或SMLD的SDE十分复杂是研究生阶段课程，但这里的微分方程简单到了初中数学的程度，而且还是ODE形式。但仔细观察我们就发现，现实完全不是这种情况。我都有已经有了 $X_1$ ，我要ODE做什么？观察变身过程吗？变身过程的确可以模拟，很可惜的是我们现在做的是生成！
这里我们改写一下，我们先训练条件向量场速度模型 $v_t(x,\theta)$ ，那么有
$$\frac{\mathrm{d}}{\mathrm{d}t} = v_t(Z_{t},\theta),Z_0\sim \pi_0 \tag{2.4.10}$$
理论上，通过不断计算从0一直到 $t$ 就有 $Z_1\sim\pi_1$ 。训练 $v_t(x,\theta)$ 模型的损失函数也很简单：
$$\arg\min_{v} \int_0^1 \mathbb{E}[|| X_1-X_0 - v_t(X_t,\theta) ||^2] \mathrm{d} t \tag{2.4.11}$$
下一节，我们将详细讲述如何走直线。