### 1.6.0 关键点复习
我们先复习一下上一节（1.5节）的知识。我们介绍了附加三个约束的多层VAE模型，即VDM模型。它是DDPM（Denoising Diffusion Probabilistic Models，去噪扩散概率模型）的主干网络。
从单个图像演变过程的角度讨论，扩散加噪过程就是不断给图像添加噪声，整体约添加1000步，直至图像被加噪成趋近于纯噪声。扩散加噪过程从头到尾是一个马尔可夫链，该过程由 $q(\mathbf{x}_t|\mathbf{x}_{t - 1})$ 标记。若用参数 $\phi$ 表示加噪模型，可用 $q_\phi(\mathbf{x}_t|\mathbf{x}_{t - 1})$ 表示这个加噪过程。由于VDM的第二条约束规则，均值和方差是预先设定的高斯分布，该过程因此可以不再单独训练，所以在DDPM过程中，一直被记为 $q(\mathbf{x}_t|\mathbf{x}_{t - 1})$ 。
逆扩散去噪过程是从纯噪声生成图像的过程，用 $p(\mathbf{x}_{t - 1}|\mathbf{x}_t)$ 标记。若用参数 $\theta$ 表示去噪模型，可用 $p_\theta(\mathbf{x}_{t - 1}|\mathbf{x}_t)$ 表示这个去噪过程。很遗憾，这里的去噪参数无法直接得到，所以讨论模型训练时，该过程的参数 $\theta$ 不能去掉。整体过程如下图所示。 

![](../images/1.14.jpg)
（扩散过程）
> [!Warning]
> 敏锐的同学发现，这里的 $x$ 参数不再用普通字体格式表示，而是用黑体 $\mathbf{x}$ 记录。因为从这里开始，我们讨论的目标很明确，就是图片向量、视频图片等向量数据。

下面，我们以刚刚推导出来的内容为基础进行推论，并结合原始DDPM代码，进行理论和实际结合的讲解。本段主要内容解读自《Denoising Diffusion Probabilistic Models》[2]
### 1.6.1 前向过程-扩散加噪
DDPM的扩散加噪过程如下：
1. $\mathbf{x}_0$ 为原始图像，$\mathbf{x}_t$ 为加 $t$ 步噪声后的图像，噪声加到最后（第 $T$ 步）为 $\mathbf{x}_T$ 
2. 图像加噪声为 $q(\mathbf{x}_t|\mathbf{x}_{t-1})$ 操作，意为从 $\mathbf{x}_{t-1}$ 加噪声成 $\mathbf{x}_t$ ；相似的图像降噪为 $p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)$ 操作，意为从 $\mathbf{x}_t$ 降噪声成 $\mathbf{x}_{t-1}$ 
3. 第 $t$ 时间步添加的噪声记为 $\epsilon_t$ ，添加的强度用参数 $\alpha_t$ 来控制 ，其中要求 $0<\beta_t<<\alpha_t<1$ ，且 $\beta_t+\alpha_t=1$ 。在DDPM论文中又加了一个参数 $\beta_t$ 参数，但这个参数我们在本节中基本用不到，并且 $\beta_t$ 能表示的变量 $\alpha_t$ 也能表示。但是在后面的推理中，我们会发现 $\beta_t$ 的用处。
此时，图像加噪过程就很可以直接地得出：
$$\begin{align}
\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1-\alpha_t}\epsilon_t  \tag{1.6.1} \\
\text{with}: \epsilon_t \sim \mathcal{N}(\epsilon;0,I) \tag{}
\end{align}$$
经过上一节的公式（1.5.17）的推理训练，我们也可以计算得到：
$$
\begin{align}
\mathbf{x}_t&=\sqrt{\alpha_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t-1}^*  \\
&=\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\epsilon_0  \tag{1.6.2} \\
q(\mathbf{x}_t)&=q(\mathbf{x}_t|\mathbf{x}_0)\sim \mathcal{N}(\mathbf{x}_t;\sqrt{\bar{\alpha}_t}\mathbf{x}_0,(1-\bar{\alpha}_t)I) \tag{1.6.3}
\end{align}
$$
这一段对应的python的代码也很直接。其中 (sqrt_alphas_cumprod, t) 就是 $\sqrt{\bar{\alpha}_t}$ ，(sqrt_one_minus_alphas_cumprod, t) 就是 $\sqrt{1-\bar{\alpha}_t}$ 。
```python
def q_sample(self, x_start, t, noise=None):
	noise = default(noise, lambda: torch.randn_like(x_start))
	return (
		extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
		extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
	)
```
### 1.6.2 基于噪声的损失函数
最终，在VDM优化公式（1.5.26）中，我们发现VDM的损失函数就是让以 $\theta$ 为参数的模型生成图片 $\hat{\mathbf{x}}_{\theta}(\mathbf{x}_t,t)$ 与原始图片 $\mathbf{x}_0$ 更接近。
$$\arg\min_{\theta} \frac{1}{2}\frac{\bar{\alpha}_{t-1}-\bar{\alpha}_t}{(1-\bar{\alpha}_{t-1})(1-\bar{{\alpha}}_{t})} \left[\left \Vert \hat{\mathbf{x}}_{\theta}(\mathbf{x}_t,t)-{x}_{0} \right \Vert_2^2 \right] \tag{1.5.26}$$
但！这种公式近乎无用。“生成结果与原图表现一致”，这种思想不需要推导就能想出来。而且还有一个要命问题：我们本来就不知道原始图像的分布，在做预测生成时，按照什么分布初始化原始模型都是一个很问题。如果初始分布与目标分布相差极大，会导致整体训练的崩溃。因此DDPM使用噪声预测的方法做为损失函数，完成DDPM的模型优化。这样的选择有一个非常大的好处：这里的噪声都是高斯分布，我们在做模型初始化时，大体方向不会走偏。下面，我们就开始改造损失函数。

首先，我们再快速回顾上一节（1.5节）的VDM的通用ELBO推导公式（1.5.13）
$$
\begin{align}
\log p(x)&\geq  \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \Big[\log{\frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}} \Big] \\
&= \underbrace{\mathbb{E}_{q(\mathbf{x}_{1}|\mathbf{x}_0)} [ \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)]}_{重建项} -   \underbrace{D_{KL}(q(\mathbf{x}_T|\mathbf{x}_0)||p(\mathbf{x}_T))}_{先验匹配项} - \underbrace{\sum_{t=2}^{T} \mathbb{E}_{q(\mathbf{x}_t|\mathbf{x}_0)} [D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))]}_{去噪匹配项}
\end{align}
$$
我们知道 $\mathbb{E}_{q(\mathbf{x}_t|\mathbf{x}_0)} [D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))]$ 是与时间 $t$ 直接有关的去噪匹配项，计算程度直接决定了ELBO的计算程度。我们希望尽可能地将**近似去噪分布** $p_θ(\mathbf{x}_{t−1}|\mathbf{x}_t)$ 与**真值去噪分布** $q(\mathbf{x}_{t−1}|\mathbf{x}_t,\mathbf{x}_0)$ 相匹配，才能做好生成模型的预测。同时在VDM中的公式（1.5.20）我们知道：
$$
q(\mathbf{x}_{t−1}|\mathbf{x}_t,\mathbf{x}_0)\propto \mathcal{N}(\mathbf{x}_{t-1};\underbrace{\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})\mathbf{x}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\mathbf{x}_{0}}{1-\bar{{\alpha}}_{t}}}_{{{\mu}}_q(\mathbf{x}_t,\mathbf{x}_0)},\underbrace{\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}}}_{{{\Sigma}}_{q}(t)}) \tag{1.5.20}
$$
我们注意到均值，方差可写做：
$$
\begin{align}
\mu_q(\mathbf{x}_t,\mathbf{x}_0)&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})\mathbf{x}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\mathbf{x}_{0}}{1-\bar{{\alpha}}_{t}}  \tag{1.6.4} \\
σ_q^2(t)&=\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} \tag{1.6.5}
\end{align} 
$$
因为要做噪声损失，我们需要在这里把 $\mathbf{x}_0$ 消去，在等式（1.6.3） $\mathbf{x}_t =\sqrt{\overline{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\overline{\alpha}_t}\epsilon_0$中，将 $\mathbf{x}_0$ 的推导变成：
$$
\mathbf{x}_0 = \frac{\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}} \tag{1.6.6}
$$
带入均值可得
$$
\begin{align}
\mu_q(\mathbf{x}_t,\mathbf{x}_0)&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})\mathbf{x}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\frac{\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}}{1-\bar{{\alpha}}_{t}} \\
&= \frac{1}{\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{1.6.7}
\end{align}
$$
我们根据模仿原则，用未知 $\mathbf{x}_0$ 值的**近似去噪分布** $p_θ(\mathbf{x}_{t−1}|\mathbf{x}_t)$ 来近似已知原始图片 $\mathbf{x}_0$ 的**真值去噪分布** $q(\mathbf{x}_{t−1}|\mathbf{x}_t,\mathbf{x}_0)$ ，设置近视去噪均值 $\mu_\theta(\mathbf{x}_t,t)$ 为：
$$
\mu_\theta(\mathbf{x}_t,t) = \frac{1}{\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(\mathbf{x}_t,t) \tag{1.6.8}
$$
其中 $\hat{\epsilon}_θ(\mathbf{x}_t,t)$ 这种带尖角帽的参数依然是用神经网络模拟的噪声网络，根据噪声预测的优化策略，我们有
$$
\begin{align}
&~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\Vert p_{{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_t))\\
&=\arg\min_{{{\theta}}} D_{\text{KL}}(\mathcal{N} (\mathbf{x}_{t-1}; μ_q, Σ_q(t)) \Vert \mathcal{N} (\mathbf{x}_{t-1}; μ_{{\theta}}, Σ_q(t))) \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Vert {\mu}_{{\theta}} − {\mu}_q \Vert_2^2 \right] \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1}{\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(\mathbf{x}_t,t) − \frac{1}{\sqrt{\alpha_t}}\mathbf{x}_t + \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \Big\Vert_2^2 \right] \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\hat{\epsilon}_\theta(\mathbf{x}_t,t) \Big\Vert_2^2 \right]  \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \left[ \Big\Vert \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}(\epsilon_0 - \hat{\epsilon}_\theta(\mathbf{x}_t,t)) \Big\Vert_2^2 \right]  \\
&=\arg\min_{{{\theta}}} \frac{1}{2σ_q^2 (t)} \frac{(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_t)\alpha_t} \left[ \Big\Vert (\epsilon_0 - \hat{\epsilon}_\theta(\mathbf{x}_t,t)) \Big\Vert_2^2 \right] \tag{1.6.9} \\
\end{align}
$$
此时我们发现只要通过拉进 $\epsilon_t$ 与 $\epsilon_\theta(\mathbf{x}_t,t)$ 的距离的方式就可以训练参数 $\theta$。这就是DDPM利用噪声间MSE Loss 即可完成优化损失函数的设计：
$$ \mathcal{Loss} =  ||\epsilon_t-\epsilon_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t,t)||^2 \tag{1.6.10}
$$
### 1.6.3 DDPM训练过程

| 训练过程伪代码                                                                                                                                                  |
| -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1: repeat                                                                                                                                                |
| 2:    $\mathbf{x}_0 \sim q(\mathbf{x}_0),t\sim \text{Uniform}(\{1,2,...,T\}),\epsilon \sim \mathcal{N}(0,I)$                                                               |
| 3:    使用梯度下降逐步优化 $\nabla_\theta \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ |
| 4: until 收敛                                                                                                                                              |
表1.1 训练过程伪代码
上表1.1为原论文的训练过程，该过程比较简单：
1.  循环直到收敛
	1. 从数据集中选取 $\mathbf{x}_0$ ，这就是原始图片；随机选取时间戳 t，它代表扩散模型需要扩散的轮数；生成t个高斯噪声，每个都是 $\epsilon_t\in\mathcal{N}(0, \mathbf{I})$
	2. 调用模型 $ϵ_θ$（这里是UNet网络）预估 $\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)$
	3. 计算噪声之间的 MSE Loss: $\mathcal{Loss} =  \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ 并梯度下降优化UNet网络。
对应python 训练代码如下：
```python
class GaussianDiffusionTrainer(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unet网络
        self.T = T

        self.register_buffer(
            'betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        self.register_buffer(
            'sqrt_alphas_bar', torch.sqrt(alphas_bar))
        self.register_buffer(
            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))

    def forward(self, x_0):
        """
        Algorithm 1.
        """
        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)
        noise = torch.randn_like(x_0)
        x_t = (
            extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 +
            extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise)
        loss = F.mse_loss(self.model(x_t, t), noise, reduction='none')
        return loss
```
### 1.6.4 DDPM模型采样过程
根据（1.6.7）的公式更改了一下（1.5.20）。
$$
\begin{align}
q(\mathbf{x}_{t−1}|\mathbf{x}_t,\mathbf{x}_0) &\propto \mathcal{N}(\mathbf{x}_{t-1};\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1})\mathbf{x}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\mathbf{x}_{0}}{1-\bar{{\alpha}}_{t}},\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}})  \\
&=\mathcal{N}(\mathbf{x}_{t-1};\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}}\epsilon_0),\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}})  \\
\end{align}
$$
此时，在我们再次强调一下我们的核心目标：
用未知 $\mathbf{x}_0$ 原始值的**近似去噪分布** $p_θ(\mathbf{x}_{t−1}|\mathbf{x}_t)$ 来近似已知原始图片 $\mathbf{x}_0$ 的**真值去噪分布** $q(\mathbf{x}_{t−1}|\mathbf{x}_t,\mathbf{x}_0)$ 
那么 $p_θ(\mathbf{x}_{t−1}|\mathbf{x}_t)$ 可以尽可能的仿作：
$$
p_\theta({x}_{t-1} \vert {x}_t) = \mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t,t)),\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}}I)
$$
我们知道 $\mathbf{x}_{t-1} \sim p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)$ ，按照初中的规则，我们可以将其化为正态分布的格式，步骤如下：
$$
\begin{align}
& \frac{\mathbf{x}_{t-1} - \mu}{\sigma} \sim \mathcal{N}(0,I)=z \\
& \mathbf{x}_{t-1} = \mu + \sigma z \\
& \mathbf{x}_{t-1} =\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z \tag{1.6.11}
\end{align}
$$
在DDPM中，用一个新的符号 $z$ 代替标准正态分布噪声，虽然本质与 $\epsilon$ 相同，但实际含义不一样。伪代码如表1.2所示：

| 前向推理采样算法伪代码                                                                                                                      |
| -------------------------------------------------------------------------------------------------------------------------------- |
| 1: $\mathbf{x}_T \sim \mathcal{N}(0,I)$                                                                                                   |
| 2: for $t=T,...,1$ do:                                                                                                           |
| 3:     $z \sim \mathcal{N}(0,I)$ if $t>1$ ， else $z=0$                                                                           |
| 4:     $\mathbf{x}_{t-1} =\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t-\frac{1- \alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t,t)) + \sigma_t z$ |
| 5: end for                                                                                                                       |
| 6: return $\mathbf{x}_0$                                                                                                                  |
表1.2 采样算法伪代码

此时已经训练出来了 $\epsilon_θ$ （这里是UNet网络），所以在下面的推理过程中 $ϵ_θ(\mathbf{x}_t,t)$ 是已知的。假设我用推理的过程中扩散T步，那么从T步开始逆向回推，每一步有如下操作：
1. 初始化最终的扩散状态 $\mathbf{x}_T$ 为纯高斯噪声，从这个状态开始进行反推。
2. 从 $t=T$ 步开始，每步减一，直到 $t=1$ ：
	1. 如果是最后一轮循环 $t=1$ ，噪声 $z = 0$ ；如果 $t > 1$ 时，即可取随机噪声 $z\in\mathcal{N}(0, \mathbf{I})$ 。
	2. 因为公式（1.6.11）推论 $\mathbf{x}_{t-1} =\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z$

3. 最后一步返回 $\mathbf{x}_0$
对应的python代码如下，同样很清晰：
```python
class GaussianDiffusionSampler(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unet
        self.T = T

        self.register_buffer('betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)
        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]

        self.register_buffer('coeff1', torch.sqrt(1. / alphas))
        self.register_buffer('coeff2', self.coeff1 * (1. - alphas) / torch.sqrt(1. - alphas_bar))

        self.register_buffer('posterior_var', self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))

    def predict_xt_prev_mean_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            extract(self.coeff1, t, x_t.shape) * x_t -
            extract(self.coeff2, t, x_t.shape) * eps
        )

    def p_mean_variance(self, x_t, t):
        # below: only log_variance is used in the KL computations
        var = torch.cat([self.posterior_var[1:2], self.betas[1:]])
        var = extract(var, t, x_t.shape)

        eps = self.model(x_t, t)
        xt_prev_mean = self.predict_xt_prev_mean_from_eps(x_t, t, eps=eps)

        return xt_prev_mean, var

    def forward(self, x_T):
        """
        Algorithm 2.
        """
        x_t = x_T
        for time_step in reversed(range(self.T)):
            print(time_step)
            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step
            mean, var= self.p_mean_variance(x_t=x_t, t=t)
            # no noise when t == 0
            if time_step > 0:
                noise = torch.randn_like(x_t)
            else:
                noise = 0
            x_t = mean + torch.sqrt(var) * noise # μ+σ*z
            assert torch.isnan(x_t).int().sum() == 0, "nan in tensor."
        x_0 = x_t
        return torch.clip(x_0, -1, 1)
```
