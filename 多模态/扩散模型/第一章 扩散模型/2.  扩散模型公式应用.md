åœ¨æ·±å…¥æ¢è®¨æ‰©æ•£æ¨¡å‹çš„ç†è®ºåŸºç¡€ä¹‹åï¼Œæœ¬ç« å°†èšç„¦äºä¼¼ç„¶æ¨¡å‹å’Œé™å™ªæ‰©æ•£æ¨¡å‹ï¼ˆDenoising Diffusion Probabilistic Modelsï¼ŒDDPMï¼‰ï¼Œä»¥åŠåŸºäºåˆ†æ•°æ¨¡å‹çš„å™ªå£°æ§åˆ¶åˆ†æ•°æ–¹ç¨‹ï¼ˆNoise Conditional Score Networksï¼ŒNCSNï¼‰çš„è”ç³»ã€‚æˆ‘ä»¬å°†ä»ç¬¬ä¸€ç« çš„åŸºç¡€çŸ¥è¯†å‡ºå‘ï¼Œè¿›ä¸€æ­¥æ­ç¤ºè¿™äº›æ¨¡å‹å¦‚ä½•åœ¨ç”Ÿæˆæ¨¡å‹é¢†åŸŸå†…æä¾›å¼ºå¤§çš„ç†è®ºæ”¯æŒå’Œå®é™…åº”ç”¨ã€‚
## 2.1 ä¼¼ç„¶æ¨¡å‹ä¸DDPM

ä¼¼ç„¶æ¨¡å‹åœ¨ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ä¸­æ‰®æ¼”ç€æ ¸å¿ƒè§’è‰²ï¼Œå®ƒä»¬é€šè¿‡æœ€å¤§åŒ–è§‚æµ‹æ•°æ®çš„ä¼¼ç„¶å‡½æ•°æ¥ä¼°è®¡æ¨¡å‹å‚æ•°ã€‚åœ¨ç¬¬ä¸€ç« ç¬¬1èŠ‚ä¸­ï¼Œæˆ‘ä»¬å¾—çŸ¥æ‰©æ•£æ¨¡å‹æ¥æºäºç‰©ç†å­¦çš„æ‰©æ•£è¿‡ç¨‹ã€‚åœ¨ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œå®ƒæ¼”åŒ–ä¸ºä»é«˜æ–¯çº¯å™ªå£°æ•°æ®é€æ¸å¯¹æ•°æ®è¿›è¡Œå»å™ªçš„è¿‡ç¨‹ã€‚å¦‚æœä»å•ä¸ªå›¾åƒè¿‡ç¨‹çš„è§‚ç‚¹æ¥è®¨è®ºï¼Œæ‰©æ•£è¿‡ç¨‹æ˜¯ä¸æ–­å¾€å›¾åƒä¸ŠåŠ å™ªå£°ç›´åˆ°å›¾åƒå˜æˆä¸€ä¸ªçº¯å™ªå£°ï¼Œæ‰©æ•£è¿‡ç¨‹ä»å¼€å¤´åˆ°æœ€åæ˜¯ä¸€ä¸ªé©¬å°”å¯å¤«é“¾ï¼Œè¯¥è¿‡ç¨‹ç”± $q_\phi(x_t|x_{t-1})$ æ¥æ ‡è®°ã€‚åˆå› ä¸ºVDMç¬¬äºŒæ¡çº¦æŸè§„åˆ™ï¼Œå› ä¸ºå‡å€¼å’Œæ–¹å·®æ˜¯é¢„å…ˆè®¾å®šçš„é«˜æ–¯åˆ†å¸ƒï¼Œè¯¥è¿‡ç¨‹ä¸å†ç”±å‚æ•° $\phi$ å‚æ•°åŒ–ï¼Œæ•…è®°ä¸º $q(x_t|x_{t-1})$ ã€‚é€†æ‰©æ•£è¿‡ç¨‹æ˜¯ä»çº¯å™ªå£°ç”Ÿæˆä¸€å¼ å›¾åƒçš„è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹ç”¨ $p_\theta(x_{t-1}|x_t)$ æ¥æ ‡è®°ã€‚æ•´ä½“è¿‡ç¨‹å¦‚ä¸‹å›¾2.1 ã€‚
![](images/2.1.1.jpg)
å›¾2.1 æ‰©æ•£è¿‡ç¨‹

æˆ‘ä»¬ä½¿ç”¨ç¬¬ä¸€ç« ç¬¬1èŠ‚çš„æ‰©æ•£æ¨¡å‹åŸºç¡€è¿›è¡Œæ¨è®ºï¼Œå¹¶ç»“åˆåŸå§‹å®ç°ä»£ç DDPMï¼Œç†è®ºè”åˆå®é™…è¿›è¡Œè¯¦ç»†è®²è§£ã€‚æœ¬æ–‡ä¸»è¦éƒ¨åˆ†æ¥è‡ªã€ŠDenoising Diffusion Probabilistic Modelsã€‹[1]
### 2.1.1 DDPMå‰å‘è¿‡ç¨‹-æ··å…¥å™ªå£°
åœ¨æ¨ç†ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆé‡ç‚¹å›é¡¾ä¸€ä¸‹ä¸Šä¸€èŠ‚çš„å†…å®¹ã€‚
1. $x_0$ ä¸ºåŸå§‹å›¾åƒï¼Œ$x_t$ ä¸ºåŠ tæ­¥å™ªå£°åçš„å›¾åƒï¼Œå™ªå£°åŠ åˆ°æœ€åï¼ˆç¬¬Tæ­¥ï¼‰ä¸º $x_T$ 
2. å›¾åƒåŠ å™ªå£°ä¸º $q(x_t|x_{t-1})$ æ“ä½œï¼Œæ„ä¸ºä» $x_{t-1}$ åŠ å™ªå£°æˆ $x_t$ ï¼›å›¾åƒé™å™ªä¸º $p_\theta(x_{t-1}|x_t)$ æ“ä½œï¼Œæ„ä¸ºä» $x_t$ é™å™ªå£°æˆ $x_{t-1}$ 
3. æ¯ä¸€æ—¶é—´æ­¥åŠ å™ªå£° $\epsilon_t$ï¼ˆæˆ–å»å™ªå£°ï¼‰éƒ½æœ‰å‚æ•°å¯¹ $\alpha_t$ ï¼Œå…¶ä¸­æœ‰ $0<\beta_t<<\alpha_t<1$ ï¼Œä¸” $\beta_t+\alpha_t=1$ ã€‚DDPMå¤šä¸€ä¸ª $\beta_t$ å‚æ•°ï¼Œä¸ºäº†æ–¹ä¾¿
é‚£ä¹ˆï¼Œå›¾åƒåŠ å™ªè¿‡ç¨‹å°±å¾ˆç›´æ¥ï¼Œæ ¹æ®ç¬¬ä¸€ç« ç¬¬ä¸€èŠ‚çš„å…¬å¼ï¼ˆ63ï¼‰
$$
\begin{align}
x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_t  \tag{2.1} \\
\text{with}: \epsilon_t \sim \mathcal{N}(\epsilon;0,I) 
\end{align}
$$
åŒç†ï¼Œç»è¿‡å…¬å¼ï¼ˆ64-73ï¼‰çš„è®¡ç®—æ¨ç†ï¼Œå¯ä»¥å¾—åˆ°ï¼š
$$
\begin{align}
x_t&=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t-1}^*  \\
&=\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon_0  \tag{2.2} \\
q(x_t)&=q(x_t|x_0)\sim \mathcal{N}(x_t;\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I) \tag{2.3}
\end{align}
$$
è¿™ä¸€æ®µå¯¹åº”çš„pythonçš„ä»£ç ä¹Ÿå¾ˆç›´æ¥ã€‚å…¶ä¸­ (sqrt_alphas_cumprod, t) å°±æ˜¯ $\sqrt{\bar{\alpha}_t}$ ï¼Œ(sqrt_one_minus_alphas_cumprod, t) å°±æ˜¯ $\sqrt{1-\bar{\alpha}_t}$ ã€‚
```python
def q_sample(self, x_start, t, noise=None):
	noise = default(noise, lambda: torch.randn_like(x_start))
	return (
		extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
		extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
	)
```

### 2.1.2 DDPMåå‘è¿‡ç¨‹
å›é¡¾ç¬¬ä¸€ç« ç¬¬1èŠ‚çš„VDMçš„é€šç”¨ELBOæ¨å¯¼å…¬å¼ï¼ˆ51-62ï¼‰ï¼Œ
$$
\begin{align}
\log p(x)&\geq  \mathbb{E}_{q(x_{1:T}|x_0)} \Big[\log{\frac{p(x_{0:T})}{q(x_{1:T}|x_0)}} \Big] \\
&= \underbrace{\mathbb{E}_{q(x_{1}|x_0)} [ \log p_\theta(x_0 | x_1)]}_{é‡å»ºé¡¹} -   \underbrace{D_{KL}(q(x_T|x_0)||p(x_T))}_{å…ˆéªŒåŒ¹é…é¡¹} - \underbrace{\sum_{t=2}^{T} \mathbb{E}_{q(x_t|x_0)} [D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t))]}_{å»å™ªåŒ¹é…é¡¹} \tag{2.4}
\end{align}
$$
æˆ‘ä»¬çŸ¥é“ $\mathbb{E}_{q(x_t|x_0)} [D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t))]$ æ˜¯ä¸æ—¶é—´ $t$ ç›´æ¥æœ‰å…³çš„å»å™ªåŒ¹é…é¡¹ï¼Œè®¡ç®—ç¨‹åº¦ç›´æ¥å†³å®šäº†ELBOçš„è®¡ç®—ç¨‹åº¦ã€‚æˆ‘ä»¬å¸Œæœ›å°½å¯èƒ½åœ°å°†**è¿‘ä¼¼å»å™ªåˆ†å¸ƒ** $p_Î¸(x_{tâˆ’1}|x_t)$ ä¸**çœŸå€¼å»å™ªåˆ†å¸ƒ** $q(x_{tâˆ’1}|x_t,x_0)$ ç›¸åŒ¹é…ï¼Œæ‰èƒ½åšå¥½ç”Ÿæˆæ¨¡å‹çš„é¢„æµ‹ã€‚åŒæ—¶ åœ¨VDMä¸­ï¼Œç”±ç¬¬ä¸€ç« ç¬¬1èŠ‚çš„å…¬å¼ï¼ˆ74-87ï¼‰æˆ‘ä»¬çŸ¥é“ï¼š
$$
q(x_{tâˆ’1}|x_t,x_0)\propto \mathcal{N}({{x}}_{t-1};\underbrace{\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}}}_{{{\mu}}_q({{x}}_t,{{x}}_0)},\underbrace{\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}}}_{{{\Sigma}}_{q}(t)}) \tag{2.5}
$$
æˆ‘ä»¬æ³¨æ„åˆ°å‡å€¼ï¼Œæ–¹å·®å¯å†™åšï¼š
$$
\begin{align}
\mu_q(x_t,x_0)&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}}  \tag{2.6} \\
Ïƒ_q^2(t)&=\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} \tag{2.7}
\end{align} 
$$
å› ä¸ºDDPMç”¨çš„æ˜¯å™ªå£°æ¨å¯¼æ¨¡å¼ï¼Œå°†å¦‚ä¸‹å…¬å¼ï¼ˆ105ï¼‰ $x_0 = \frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}$ å¸¦å…¥å‡å€¼å¯å¾—
$$
\begin{align}
\mu_q(x_t,x_0)&=\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t)\frac{x_t-\sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}}{1-\bar{{\alpha}}_{t}} \\
&= \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}\sqrt{\alpha_t}}\epsilon_0 \tag{2.8}
\end{align}
$$
æ ¹æ®å™ªå£°é¢„æµ‹çš„ä¼˜åŒ–ç­–ç•¥ï¼Œæˆ‘ä»¬æœ‰
$$
\begin{align}
&~~~~\arg\min_{{{\theta}}} D_{\text{KL}}(q({{x}}_{t-1}|{{x}}_t,{{x}}_0)\Vert p_{{\theta}}({{x}}_{t-1}|{{x}}_t))\\
&=\arg\min_{{{\theta}}} \frac{1}{2Ïƒ_q^2 (t)} \frac{(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_t)\alpha_t} \left[ \Big\Vert (\epsilon_0 - \hat{\epsilon}_\theta(x_t,t)) \Big\Vert_2^2 \right] \\
&=\arg\min_{{{\theta}}} \frac{1}{2Ïƒ_q^2 (t)} \frac{(1-{\alpha}_t)^2}{(1-\bar{{\alpha}}_t)\alpha_t} \left[ \Big\Vert (\epsilon_0 - \hat{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t,t)) \Big\Vert_2^2 \right] \tag{2.9} \\
\end{align}
$$
æ­¤æ—¶æˆ‘ä»¬å‘ç°åªè¦é€šè¿‡æ‹‰è¿› $\epsilon_t$ ä¸ $\epsilon_\theta(x_t,t)$ çš„è·ç¦»çš„æ–¹å¼å°±å¯ä»¥è®­ç»ƒå‚æ•° $\theta$ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬åˆ©ç”¨å™ªå£°é—´MSE Loss å³å¯å®Œæˆä¼˜åŒ–æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼š
$$ \mathcal{Loss} =  ||\epsilon_t-\epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t,t)||^2 \tag{2.10}
$$
### 2.1.3 è®­ç»ƒè¿‡ç¨‹
| è®­ç»ƒè¿‡ç¨‹ä¼ªä»£ç                                                                                                                                                   |
| -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1: repeat                                                                                                                                                |
| 2:    $x_0 \sim q(x_0),t\sim \text{Uniform}(\{1,2,...,T\}),\epsilon \sim \mathcal{N}(0,I)$                                                               |
| 3:    ä½¿ç”¨æ¢¯åº¦ä¸‹é™é€æ­¥ä¼˜åŒ– $\nabla_\theta \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ |
| 4: until æ”¶æ•›                                                                                                                                              |
è¡¨2.1 è®­ç»ƒè¿‡ç¨‹ä¼ªä»£ç 
ä¸Šè¡¨2.1ä¸ºåŸè®ºæ–‡çš„è®­ç»ƒè¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼š
1.  å¾ªç¯ç›´åˆ°æ”¶æ•›
	1. ä»æ•°æ®é›†ä¸­é€‰å– $x_0$ ï¼Œè¿™å°±æ˜¯åŸå§‹å›¾ç‰‡ï¼›éšæœºé€‰å–æ—¶é—´æˆ³ tï¼Œå®ƒä»£è¡¨æ‰©æ•£æ¨¡å‹éœ€è¦æ‰©æ•£çš„è½®æ•°ï¼›ç”Ÿæˆtä¸ªé«˜æ–¯å™ªå£°ï¼Œæ¯ä¸ªéƒ½æ˜¯ $\epsilon_t\in\mathcal{N}(0, \mathbf{I})$
	2. è°ƒç”¨æ¨¡å‹ $Ïµ_Î¸$ï¼ˆè¿™é‡Œæ˜¯UNetç½‘ç»œï¼‰é¢„ä¼° $\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)$
	3. è®¡ç®—å™ªå£°ä¹‹é—´çš„ MSE Loss: $\mathcal{Loss} =  \left\|\epsilon_t-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t, t\right)\right\|^2$ å¹¶æ¢¯åº¦ä¸‹é™ä¼˜åŒ–UNetç½‘ç»œã€‚
å¯¹åº”python è®­ç»ƒä»£ç å¦‚ä¸‹ï¼š
```python
class GaussianDiffusionTrainer(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unetç½‘ç»œ
        self.T = T

        self.register_buffer(
            'betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        self.register_buffer(
            'sqrt_alphas_bar', torch.sqrt(alphas_bar))
        self.register_buffer(
            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))

    def forward(self, x_0):
        """
        Algorithm 1.
        """
        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)
        noise = torch.randn_like(x_0)
        x_t = (
            extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 +
            extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise)
        loss = F.mse_loss(self.model(x_t, t), noise, reduction='none')
        return loss
```
### 2.1.4 æ¨ç†è¿‡ç¨‹
DDPMçš„å…¬å¼æ˜¯æ ¹æ®ï¼ˆ2.5ï¼Œ2.8ï¼‰çš„å…¬å¼æ›´æ”¹äº†ä¸€ä¸‹ã€‚
$$
\begin{align}
q(x_{tâˆ’1}|x_t,x_0) &\propto \mathcal{N}({{x}}_{t-1};\frac{\sqrt{{\alpha}_t}(1-\bar{{\alpha}}_{t-1}){{x}}_t+\sqrt{\bar{{\alpha}}_{t-1}}(1-{\alpha}_t){{x}}_{0}}{1-\bar{{\alpha}}_{t}},\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}})  \\
&=\mathcal{N}({{x}}_{t-1};\frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-{\alpha}_t}{\sqrt{1-\bar{{\alpha}}_t}}\epsilon_0),\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}} {{I}})  \\
\end{align}
$$
æ­¤æ—¶ï¼Œåœ¨æˆ‘ä»¬å†æ¬¡å¼ºè°ƒä¸€ä¸‹æˆ‘ä»¬åœ¨ç¬¬ä¸€ç« æåˆ°çš„æ ¸å¿ƒç›®æ ‡ï¼š
ç”¨æœªçŸ¥ $x_0$ åŸå§‹å€¼çš„**è¿‘ä¼¼å»å™ªåˆ†å¸ƒ** $p_Î¸(x_{tâˆ’1}|x_t)$ æ¥è¿‘ä¼¼å·²çŸ¥åŸå§‹å›¾ç‰‡ $x_0$ çš„**çœŸå€¼å»å™ªåˆ†å¸ƒ** $q(x_{tâˆ’1}|x_t,x_0)$ 
é‚£ä¹ˆ $p_Î¸(x_{tâˆ’1}|x_t)$ å¯ä»¥å°½å¯èƒ½çš„ä»¿ä½œï¼š
$$
p_\theta({x}_{t-1} \vert {x}_t) = \mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)),\frac{(1-{\alpha}_t)(1-\bar{{\alpha}}_{t-1})}{1-\bar{{\alpha}}_{t}}I)
$$
æˆ‘ä»¬çŸ¥é“ $x_{t-1} \sim p_\theta(x_{t-1}|x_t)$ ï¼ŒæŒ‰ç…§åˆä¸­çš„è§„åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åŒ–ä¸ºæ­£æ€åˆ†å¸ƒçš„æ ¼å¼ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š
$$
\begin{align}
& \frac{x_{t-1} - \mu}{\sigma} \sim \mathcal{N}(0,I)=z \\
& x_{t-1} = \mu + \sigma z \\
& x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z \tag{2.11}
\end{align}
$$
åœ¨DDPMä¸­ï¼Œç”¨ä¸€ä¸ªæ–°çš„ç¬¦å· $z$ ä»£æ›¿æ ‡å‡†æ­£æ€åˆ†å¸ƒå™ªå£°ï¼Œè™½ç„¶æœ¬è´¨ä¸ $\epsilon$ ç›¸åŒï¼Œä½†å®é™…å«ä¹‰ä¸ä¸€æ ·ã€‚ä¼ªä»£ç å¦‚è¡¨2.2æ‰€ç¤ºï¼š

| å‰å‘æ¨ç†é‡‡æ ·ç®—æ³•ä¼ªä»£ç                                                                                                                       |
| -------------------------------------------------------------------------------------------------------------------------------- |
| 1: $x_T \sim \mathcal{N}(0,I)$                                                                                                   |
| 2: for $t=T,...,1$ do:                                                                                                           |
| 3:     $z \sim \mathcal{N}(0,I)$ if $t>1$ ï¼Œ else $z=0$                                                                           |
| 4:     $x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1- \alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \sigma_t z$ |
| 5: end for                                                                                                                       |
| 6: return $x_0$                                                                                                                  |
è¡¨2.2 é‡‡æ ·ç®—æ³•ä¼ªä»£ç 

æ­¤æ—¶å·²ç»è®­ç»ƒå‡ºæ¥äº† $\epsilon_Î¸$ ï¼ˆè¿™é‡Œæ˜¯UNetç½‘ç»œï¼‰ï¼Œæ‰€ä»¥åœ¨ä¸‹é¢çš„æ¨ç†è¿‡ç¨‹ä¸­ $Ïµ_Î¸(x_t,t)$ æ˜¯å·²çŸ¥çš„ã€‚å‡è®¾æˆ‘ç”¨æ¨ç†çš„è¿‡ç¨‹ä¸­æ‰©æ•£Tæ­¥ï¼Œé‚£ä¹ˆä»Tæ­¥å¼€å§‹é€†å‘å›æ¨ï¼Œæ¯ä¸€æ­¥æœ‰å¦‚ä¸‹æ“ä½œï¼š
1. åˆå§‹åŒ–æœ€ç»ˆçš„æ‰©æ•£çŠ¶æ€ $x_T$ ä¸ºçº¯é«˜æ–¯å™ªå£°ï¼Œä»è¿™ä¸ªçŠ¶æ€å¼€å§‹è¿›è¡Œåæ¨ã€‚
2. ä» $t=T$ æ­¥å¼€å§‹ï¼Œæ¯æ­¥å‡ä¸€ï¼Œç›´åˆ° $t=1$ ï¼š
	1. å¦‚æœæ˜¯æœ€åä¸€è½®å¾ªç¯ $t=1$ ï¼Œå™ªå£° $z = 0$ ï¼›å¦‚æœ $t > 1$ æ—¶ï¼Œå³å¯å–éšæœºå™ªå£° $z\in\mathcal{N}(0, \mathbf{I})$ ã€‚
	2. å› ä¸ºå…¬å¼ï¼ˆ2.11ï¼‰æ¨è®º $x_{t-1} =\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \frac{(1-\alpha)(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}  z$

3. æœ€åä¸€æ­¥è¿”å› $x_0$
å¯¹åº”çš„pythonä»£ç å¦‚ä¸‹ï¼ŒåŒæ ·å¾ˆæ¸…æ™°ï¼š
```python
class GaussianDiffusionSampler(nn.Module):
    def __init__(self, model, beta_1, beta_T, T):
        super().__init__()

        self.model = model # Unet
        self.T = T

        self.register_buffer('betas', torch.linspace(beta_1, beta_T, T).double())
        alphas = 1. - self.betas
        alphas_bar = torch.cumprod(alphas, dim=0)
        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]

        self.register_buffer('coeff1', torch.sqrt(1. / alphas))
        self.register_buffer('coeff2', self.coeff1 * (1. - alphas) / torch.sqrt(1. - alphas_bar))

        self.register_buffer('posterior_var', self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))

    def predict_xt_prev_mean_from_eps(self, x_t, t, eps):
        assert x_t.shape == eps.shape
        return (
            extract(self.coeff1, t, x_t.shape) * x_t -
            extract(self.coeff2, t, x_t.shape) * eps
        )

    def p_mean_variance(self, x_t, t):
        # below: only log_variance is used in the KL computations
        var = torch.cat([self.posterior_var[1:2], self.betas[1:]])
        var = extract(var, t, x_t.shape)

        eps = self.model(x_t, t)
        xt_prev_mean = self.predict_xt_prev_mean_from_eps(x_t, t, eps=eps)

        return xt_prev_mean, var

    def forward(self, x_T):
        """
        Algorithm 2.
        """
        x_t = x_T
        for time_step in reversed(range(self.T)):
            print(time_step)
            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step
            mean, var= self.p_mean_variance(x_t=x_t, t=t)
            # no noise when t == 0
            if time_step > 0:
                noise = torch.randn_like(x_t)
            else:
                noise = 0
            x_t = mean + torch.sqrt(var) * noise # Î¼+Ïƒ*z
            assert torch.isnan(x_t).int().sum() == 0, "nan in tensor."
        x_0 = x_t
        return torch.clip(x_0, -1, 1)
```

## 2.2 åˆ†æ•°æ¨¡å‹ä¸NCSN
### 2.2.1 åˆ†æ•°ç”Ÿæˆæ¨¡å‹
ç¬¬ä¸€ç« ç¬¬ä¸€èŠ‚æåˆ°äº†**åˆ†æ•°ç”Ÿæˆæ¨¡å‹ï¼ˆScore-based Generative Modelï¼‰**ã€‚è¿™éƒ¨åˆ†ä¸»è¦æºäºNCSN ï¼ˆNoise Conditional Score Networksï¼‰è®ºæ–‡[2]ï¼Œå®ƒæ¥è‡ªäºå®‹é£åšå£«è¿™æ˜¯å®‹é£å‘è¡¨åœ¨ NeurIPS2019 ä¸Šé¢çš„æ–‡ç« ã€‚å®‹é£åšå£«è®¤ä¸ºç°æœ‰çš„ç”Ÿæˆæ¨¡å‹å¯ä»¥å¤§ä½“åˆ†ä¸ºä¸¤ç§[3]ï¼š**åŸºäºä¼¼ç„¶çš„æ¨¡å‹**ä¸**éšå¼ç”Ÿæˆæ¨¡å‹**ã€‚åŸºäºä¼¼ç„¶çš„æ¨¡å‹è¦ä¹ˆä¸ºä¼¼ç„¶çš„è®¡ç®—å¯¹æ¨¡å‹ç»“æ„åšå¾ˆå¼ºçš„é™åˆ¶ï¼Œè¦ä¹ˆä¾èµ–ç›®æ ‡å‡½æ•°æ¥åšâ€œè¿‘ä¼¼æå¤§ä¼¼ç„¶â€çš„è®­ç»ƒã€‚è€Œéšå¼ç”Ÿæˆæ¨¡å‹è¦æ±‚å¯¹æŠ—è®­ç»ƒï¼Œæ¨¡å‹ä¸ç¨³å®šå¾ˆå®¹æ˜“å´©æºƒã€‚ä¸ºäº†è§„é¿è¿™äº›é—®é¢˜ï¼Œå®‹é£åšå£«é€‰æ‹©ä»å¤§é‡è¢«å™ªå£°æ‰°åŠ¨çš„æ•°æ®åˆ†å¸ƒä¸­å­¦ä¹ åˆ†æ•°å‡½æ•°ï¼ˆscore functionï¼‰ï¼Œå³â€œ**steinåˆ†æ•°**â€ $\nabla _{{x}}\log p({x})$ ã€‚å¹¶ä½¿ç”¨æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦ï¼ˆLangevin dynamicsï¼‰çš„æ–¹æ³•ä»ä¼°è®¡çš„æ•°æ®åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·æ¥ç”Ÿæˆæ–°çš„æ ·æœ¬ã€‚è¿™æ ·å¾—åˆ°çš„ç”Ÿæˆæ¨¡å‹é€šå¸¸ç§°ä¸ºâ€œ**åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹**â€ï¼ˆScore-based Generative Modelsï¼ŒSGMï¼‰ã€‚
### 2.2.2 â€œåˆ†æ•°â€çš„èµ·æº
ä¼ ç»Ÿç”Ÿæˆæ¨¡å‹çš„ç›®æ ‡å°±æ˜¯è¦å¾—åˆ°æ•°æ®çš„åˆ†å¸ƒã€‚ä¾‹å¦‚ä¸€ä¸ªæ•°æ®é›† ${x_1, x_2, ..., x_N}$ çš„æ•°æ®çš„æ¦‚ç‡å¯†åº¦åˆ†å¸ƒï¼ˆæ³¨æ„ï¼Œè¿™é‡Œæ˜¯æ¦‚ç‡å¯†åº¦åˆ†å¸ƒï¼ŒPDFï¼‰ä¸º $p(x)$ ã€‚èµ·åˆæˆ‘ä»¬è®¤ä¸ºåˆå§‹çš„æ•°æ®æ˜¯æ‚ä¹±çš„ï¼Œéšæœºçš„ï¼Œæˆ‘ä»¬å¯ä»¥è®°ä¸ºï¼š
$$
p_{\theta}({x}) = \frac{e^{-f_{\theta}({x})}}{C_{\theta}},f_{\theta}({x})\in \mathbb{R} \tag{2.12}\\
$$
$\theta$ æ˜¯å‚æ•°ç”¨äºå»ºæ¨¡ï¼Œ $f_{\theta}$ è¢«ç§°ä¸ºæ ¸å¿ƒèƒ½é‡æ¨¡å‹ï¼ˆenergy-based modelï¼‰ã€‚è¿™ä¸ªå‡½æ•°å‹å°±å¾ˆåƒé«˜æ–¯å‡½æ•° $f(x)=\frac{1}{Ïƒ \sqrt{2Ï€}} \cdot e^{\frac{-(x - Î¼)^2} {2Ïƒ^2}}$ ã€‚æˆ‘ä»¬é€šè¿‡æœ€å¤§åŒ–logä¼¼ç„¶çš„æ–¹å¼ä¸­æ±‚å‚æ•°$\theta$ ã€‚å³é¦–å…ˆè®¡ç®—åŸºäºxçš„å¯¼æ•°ä¸ºï¼š
$$
\nabla _{{x}}\log(p_{\theta}({x})) = -\nabla _{{x}}f _{\theta}({x}) - \nabla _{{x}}\log C_{\theta} = -\nabla _{{x}}f _{\theta}({x}) \tag{2.13} \\
$$
å› ä¸ºCä¸æ— å…³ï¼Œæ‰€ä»¥ $\nabla _{{x}}\log C_{\theta}=0$ ã€‚è¿™é‡Œçªç„¶å‘ç°ï¼Œå¦‚æœæ±‚è§£ $\nabla _{{x}}\log p({x})$ æˆ‘ä»¬å°±ä¸éœ€æ±‚è§£å¸¸æ•°Cäº†ã€‚

é‚£ä¹ˆï¼Œè¿™ä¸ªåˆ†æ•°å…·ä½“æœ‰ä»€ä¹ˆæ„ä¹‰å‘¢ï¼Ÿä»æ•°å­¦çš„è§’åº¦å‡ºå‘æ¥çœ‹ï¼Œå®ƒæ˜¯ä¸€ä¸ªâ€œçŸ¢(å‘)é‡åœºâ€(vector field) ã€‚å‘é‡çš„æ–¹å‘æ˜¯ï¼šå¯¹äºè¾“å…¥æ•°æ®(æ ·æœ¬)æ¥è¯´ï¼Œå…¶å¯¹æ•°æ¦‚ç‡å¯†åº¦å¢é•¿æœ€å¿«çš„æ–¹å‘ã€‚ï¼ˆä¸‹å›¾ä»…ä»…æ˜¯ç¤ºæ„ï¼Œä¸ä»£è¡¨çœŸå®åœºæ™¯ï¼‰å¦‚æœåœ¨é‡‡æ ·è¿‡ç¨‹ä¸­æ²¿ç€åˆ†æ•°çš„æ–¹å‘èµ°ï¼Œå°±èƒ½å¤Ÿèµ°åˆ°æ•°æ®åˆ†å¸ƒçš„é«˜æ¦‚ç‡å¯†åº¦åŒºåŸŸï¼ˆå³ä¸ºä¸­å¿ƒï¼Œæ–¹å‘è¿‘ä¹å‚ç›´åŒºï¼‰ï¼Œæœ€ç»ˆç”Ÿæˆçš„æ ·æœ¬å°±ä¼šç¬¦åˆåŸæ•°æ®åˆ†å¸ƒã€‚
### 2.2.3  éƒä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·æ–¹æ³•

æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦ï¼ˆLangevin dynamicsï¼‰åŸæ˜¯æè¿°ç‰©ç†å­¦ä¸­å¸ƒæœ—è¿åŠ¨ï¼ˆæ‚¬æµ®åœ¨æ¶²ä½“æˆ–æ°”ä½“ä¸­çš„å¾®å°é¢—ç²’æ‰€åšçš„æ— è§„åˆ™è¿åŠ¨ï¼‰çš„å¾®åˆ†æ–¹ç¨‹ï¼Œå€Ÿé‰´åˆ°è¿™é‡Œä½œä¸ºä¸€ç§ç”Ÿæˆæ ·æœ¬çš„æ–¹æ³•ã€‚ä»ä¸€ä¸ªåˆ†å¸ƒä¸­é‡‡æ ·æ—¶ï¼Œç»å¸¸ä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚æ¦‚æ‹¬åœ°æ¥è¯´ï¼Œè¯¥æ–¹æ³•é¦–å…ˆä»å…ˆéªŒåˆ†å¸ƒéšæœºé‡‡æ ·ä¸€ä¸ªåˆå§‹æ ·æœ¬ï¼Œç„¶ååˆ©ç”¨æ¨¡å‹ä¼°è®¡å‡ºæ¥çš„åˆ†æ•°é€æ¸å°†æ ·æœ¬å‘æ•°æ®åˆ†å¸ƒçš„é«˜æ¦‚ç‡å¯†åº¦åŒºåŸŸé è¿‘ã€‚ä¸ºä¿è¯ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§ï¼Œæˆ‘ä»¬éœ€è¦é‡‡æ ·è¿‡ç¨‹å¸¦æœ‰éšæœºæ€§ã€‚å½“ç»è¿‡ä¸­æ‰€è¿°çš„åˆ†æ•°åŒ¹é…æ–¹æ³•è®­ç»ƒæ·±åº¦ç”Ÿæˆæ¨¡å‹åï¼Œå¯ä»¥ä½¿ç”¨å…·æœ‰è¿­ä»£è¿‡ç¨‹çš„æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·æ–¹æ³•ä»åˆ†å¸ƒä¸­æ¥ç”Ÿæˆæ–°çš„æ ·æœ¬ã€‚
æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·è¿‡ç¨‹æè¿°ï¼šå‡è®¾åˆå§‹æ•°æ®æ»¡è¶³å…ˆéªŒåˆ†å¸ƒÂ $x_0 \sim \pi(x)$ ï¼Œç„¶åä½¿ç”¨è¿­ä»£è¿‡ç¨‹
$$
\begin{align*}
x_{t+1}&=x_t+\frac{\epsilon}{2}\nabla _{x}\log  p\left( x \right) +\sqrt{\epsilon}\boldsymbol{z}_t, t=0,1,2,\cdots ,T\\
&=x_t+\frac{\epsilon}{2}s_{\theta}\left( x \right) +\sqrt{\epsilon}\boldsymbol{z}_t, t=0,1,2,\cdots ,T
\end{align*}
$$
å…¶ä¸­ï¼Œ $z_i \sim \mathcal{N}(0,I)$ ä¸ºæ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼Œå¯ä»¥çœ‹æˆæ˜¯å™ªå£°çš„æ¦‚å¿µã€‚ç†è®ºä¸Šï¼Œå½“ $k \rightarrow \infty, \epsilon \rightarrow 0$ ï¼Œæœ€ç»ˆç”Ÿæˆçš„æ ·æœ¬Â $x_T$ å°†ä¼šæœä»åŸæ•°æ®åˆ†å¸ƒÂ $p_{data}(x)$ï¼Œè¶‹äºæŸä¸€ä¸ªç‰¹å®šå€¼ã€‚
![](images/2.2.2.jpg)
å›¾ 2.2 ä»å·¦åˆ°å³ï¼Œå›¾ç‰‡æ¨¡æ‹Ÿçš„æ˜¯ä½¿ç”¨éƒä¹‹ä¸‡åŠ¨åŠ›å­¦åœ¨ä¸¤ä¸ªé«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œæœ€åé‡‡æ ·çš„ç»“æœå¾ˆç¬¦åˆåŸå§‹é«˜æ–¯åˆ†å¸ƒ
### 2.2.4 åˆ†æ•°ç”Ÿæˆæ¨¡å‹å…¬å¼æ¨ç†
ç°åœ¨æˆ‘ä»¬æƒ³è¦è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥ä¼°è®¡å‡ºçœŸå®çš„åˆ†å¸ƒã€‚ $s_\theta({x})$ å°±æ˜¯è¿™ä¸ªç¥ç»ç½‘ç»œçš„åˆ†æ•°ï¼ŒåŒç† $\theta$ è¿˜æ˜¯ä»£è¡¨ç½‘ç»œå‚æ•°ã€‚æˆ‘ä»¬å¯ä»¥æœ€å°åŒ–çœŸå®çš„score functionï¼Œç”¨è¿™ç§å½¢ä¼¼æ¥ä¼˜åŒ–å³å¯ã€‚
$$\mathcal{L} = \mathbb{E}_{p({x})}[||\nabla _{{x}}\log p({x}) - {s} _{\theta}({x})||^{2}] \tag{2.14}$$
ä½†æ˜¯è¿™æ ·çš„ä¸€ä¸ªlossæˆ‘ä»¬æ˜¯ç®—ä¸å‡ºæ¥çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸çŸ¥é“çœŸå®çš„$p({x})$æ˜¯ä»€ä¹ˆã€‚æˆ‘ä»¬æŠŠä¸Šé¢lossçš„æœŸæœ›æ ¹æ®ä¸Šä¸€èŠ‚å…¬å¼ï¼ˆ1.7ï¼‰å†™å¼€ï¼ŒåŒæ—¶äºŒæ¬¡èŒƒå¼é¡¹æ‰“å¼€ï¼Œå¯ä»¥å¾—åˆ°
$$
\begin{align*}\mathcal{L} =& \mathbb{E}_{p({x})}[||\nabla _{{x}}\log p({x}) - {s} _{\theta}({x})||^{2}]\\
=& \int p({x}) [||\nabla _{{x}}\log p({x})||^{2} + ||{s} _{\theta}({x})||^{2} - 2(\nabla _{{x}}\log p({x}))^{T}{s} _{\theta}({x})] d {x}\end{align*}\\
$$
ç¬¬ä¸€é¡¹å¯¹äº $\theta$ æ¥è¯´æ˜¯å¸¸æ•°å¯ä»¥å¿½ç•¥ã€‚å› ä¸ºæˆ‘ä»¬è¦ç®—ç½‘ç»œ $\theta$ çš„å‚æ•°ï¼Œä¸ $x$ æ— å…³ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠç¬¬ä¸€é¡¹å»æ‰ï¼Œä¸äºˆè€ƒè™‘ã€‚
ç¬¬äºŒé¡¹ä¸ºï¼š
$$\int p({x}) ||{s} _{\theta}({x})||^{2} d {x}$$
å¯¹äºç¬¬ä¸‰é¡¹ï¼Œè‹¥xçš„ç»´åº¦ä¸ºNåˆ™æœ‰ï¼š
$$
\begin{align*}
& -2\int p({x}) (\nabla _{{x}}\log p({x}))^{T}{s} _{\theta}({x}) d {x}\\ 
=& -2 \int p({x}) \sum\limits_{i=1}^{N}(\frac{\partial \log p({x})}{\partial {x}_{i}}{s}_{\theta_i}({x})) d {x}\\ 
=& -2 \sum\limits_{i=1}^{N} \int p({x}) \frac{1}{p({x})} \frac{\partial p({x})}{\partial {x}_{i}}{s}_{\theta_i}({x}) d {x}\\ 
=& -2 \sum\limits_{i=1}^{N} \int \frac{\partial p({x})}{\partial {x}_{i}}{s}_{\theta_i}({x}) d {x}\\ 
=& 2 \sum\limits_{i=1}^{N} - \int( \frac{\partial (p({x}){s}_{\theta_i}({x}))}{\partial {x}_{i}} d {x} + \int p({x}) \frac{\partial {s}_{\theta_i}({x})}{\partial {x}_{i}}) d {x}
\end{align*}
$$
ä¸Šé¢çš„æœ€åä¸€æ­¥æ˜¯åˆ†æ®µæ±‚ç§¯åˆ†å…¬å¼ï¼Œå› ä¸º $p(x)$ å–æé™æ˜¯0ï¼Œè¿™æ˜¯PDFçš„ç‰¹æ€§ã€‚å¯å¾—ä¸‹é¢å·¦è¾¹é‚£éƒ¨åˆ†ä¸º0ã€‚
$$
\begin{align*}
=& 2 - (p({x}){s}_{\theta_i}({x})\bigg\rvert^{\infty}_{-\infty}) + \sum\limits_{i=1}^{N}\int p({x}) \frac{\partial {s}_{\theta i}({x})}{\partial {x}_{i}} d {x}\\ 
=& 2 \sum\limits_{i=1}^{N} \int p({x}) \frac{\partial {s}_{\theta i}({x})}{\partial {x}_{i}} d {x}\\ 
=& 2\int p({x}) \sum\limits_{i=1}^{N} \frac{\partial {s}_{\theta i}({x})}{\partial {x}_{i}} d {x}\\ 
=& 2\int p({x}) \text{tr}(\nabla _{{x}}{s}_{\theta}({x})) d {x}
\end{align*}
$$
$tr(.)$ å‡½æ•°è¡¨ç¤ºçŸ©é˜µçš„è¿¹(trace)ï¼Œå³çŸ©é˜µä¸»å¯¹è§’çº¿å…ƒç´ çš„æ€»å’Œã€‚å› ä¸º $\nabla _{{x}}{s}_{\theta}({x})$ æ˜¯ä¸ªäºŒé˜¶æµ·æ£®çŸ©é˜µæ±‚å¯¼ï¼Œè¿™é‡Œåªç”¨ä¸»å¯¹è§’çº¿å°±è¡Œã€‚
æ‰€ä»¥æœ€åçš„lossæ˜¯ç¬¬äºŒå’Œç¬¬ä¸‰é¡¹çš„å’Œï¼Œå› ä¸ºæ–¹ä¾¿æ“ä½œï¼Œè®ºæ–‡ä¸­çš„Losså…¬å¼ä¹˜ä¸Šäº†1/2ï¼Œç»“æœä¸å½±å“ï¼š
$$\begin{align*} \frac{1}{2}\mathcal{L} &= \frac{1}{2}\int p({x}) ||{s} _{\theta}({x})||^{2} d {x} + \int p({x}) \text{tr}(\nabla _{{x}}{s}_{\theta}({x})) d {x}\\\\ &= \mathbb{E}_{p({x})}[||\frac{1}{2}{s} _{\theta}({x})||^{2} + \text{tr}(\nabla _{{x}}{s}_{\theta}({x}))] \tag{2.15} \end{align*}$$
å…¬å¼ä¼¼ä¹è¶Šæ¥è¶Šå¤æ‚ $tr(.)$ åˆ°åº•æ˜¯æ€ä¹ˆæ±‚ï¼Ÿä½œè€…åœ¨å™ªå£°æ¡ä»¶åˆ†æ•°ç½‘ç»œ NCSN è®ºæ–‡[3]ä¸­ç»™å‡ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚å…·ä½“åšæ³•å°±æ˜¯å¯¹åŸå§‹æ•°æ®åŠ å™ªï¼Œä½¿å¾—å…¶ç»“æœæ»¡è¶³æˆ‘ä»¬é¢„å…ˆå®šä¹‰å¥½çš„åˆ†å¸ƒï¼Œæ¯”å¦‚é«˜æ–¯åˆ†å¸ƒã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±çŸ¥é“äº†ç°åœ¨çš„æ¦‚ç‡å¯†åº¦äº†ï¼Œäºæ˜¯å°±å¯ä»¥è¿›è¡Œè®­ç»ƒã€‚å…·ä½“æ“ä½œæˆ‘ä»¬æ¥ä¸‹æ¥ä»‹ç»ã€‚
### 2.2.5  å™ªå£°æ¡ä»¶åˆ†æ•°ç½‘ç»œï¼ˆNoise Conditional Score Networksï¼ŒNCSNï¼‰
å»å™ªåˆ†æ•°åŒ¹é…ï¼ˆDenoising Score Matchingï¼ŒDSMï¼‰æ–¹æ³•æ˜¯ä½œè€…åœ¨å™ªå£°æ¡ä»¶åˆ†æ•°ç½‘ç»œ NCSN ä¸­é»˜è®¤çš„è®¡ç®—æ–¹æ³•[3]ã€‚å½“å‰çš„é—®é¢˜æ˜¯ï¼šä¸çŸ¥é“**åŸå§‹æ•°æ®åˆ†å¸ƒçš„æ¢¯åº¦å‘é‡**ã€‚æœ‰ä¸€ç§è§£é¢˜æ–¹æ³•æ˜¯ä»æ ‡å‡†é«˜æ–¯å™ªå£°ä¸­æ„å»ºæ–°åˆ†å¸ƒã€‚æˆ‘ä»¬è€ƒè™‘ä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒ $\mathcal{N}(0,ğ¼)$ ä¸­é‡‡æ ·éšæœºå™ªå£°ğœ–ï¼Œç„¶åä¹˜ä¸Šæˆ‘ä»¬é¢„å®šä¹‰çš„ $ğœ$ ï¼Œæ¥ç€åŠ åˆ°æ ·æœ¬ $ğ‘¥$ ä¸­ï¼Œä»è€Œå°±èƒ½å¾—åˆ°åŠ å™ªåçš„æ ·æœ¬ $\tilde{ğ‘¥}$ã€‚æˆ‘ä»¬æ„å»ºæ–°åˆ†å¸ƒä¸ºï¼š
$$\begin{align}
q_{\sigma}(\tilde{x}) &=\int q_Ïƒ(\tilde{x}|x) p_{data}(x) dx \tag{2.16} \\
& = \int \mathcal{N}(\tilde{x}|x,Ïƒ^2I)p_{data}(x) dx \tag{2.16+}\\
\text{and} ~ \tilde{x}&=x+\sigma\epsilon, ~ \epsilon\sim \mathcal{N}(0,I) \tag{2.17} \\
\end{align}$$å…¬å¼ï¼ˆ2.16ï¼‰çš„ç§¯åˆ†æ˜¯ä»£è¡¨é‡‡æ ·ï¼Œæœ‰äº›åœ°æ–¹ä¼šçœ‹åˆ°å…¬å¼ï¼ˆ2.16+ï¼‰çš„å½¢å¼ã€‚$p_{data}(x)$ ä»£è¡¨éœ€è¦æ‰°åŠ¨çš„æ•°æ®ã€‚$q_Ïƒ(\tilde{x}|x) \sim \mathcal{N}(\tilde{x}|x,Ïƒ^2I)$ è¡¨ç¤ºæ‰°åŠ¨å™ªå£°æ•°æ®åˆ†å¸ƒã€‚$q_{\sigma}(\tilde{x})$ å°±æ˜¯æˆ‘ä»¬æ„å»ºçš„æ–°åˆ†å¸ƒï¼Œ $\tilde{ğ‘¥}$å°±æ˜¯æˆ‘ä»¬åŠ å™ªçš„æ–°æ ·æœ¬ã€‚
NCSNçš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªæ¡ä»¶åˆ†æ•°ç½‘ç»œÂ $s_{\theta}( \tilde{x},\sigma )$Â æ¥ä¼°è®¡æ‰°åŠ¨æ•°æ®çš„åˆ†å¸ƒï¼Œå³Â 
$$
\frac{1}{2}\mathbb{E}_{q_Ïƒ(\tilde{x})}
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \nabla _{\tilde{x}} \log q_Ïƒ(\tilde{x})\Vert_2^2\Big] \tag{2.18}
$$
åœ¨DSMè®ºæ–‡[4]ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°ç›¸åº”çš„æ¨å¯¼å…¬å¼
$$
\begin{align}
& ~~~~ \frac{1}{2}\mathbb{E}_{q_Ïƒ(\tilde{x})}
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \nabla _{\tilde{x}} \log q_Ïƒ(\tilde{x})\Vert_2^2\Big] \tag{2.19} \\
&=\frac{1}{2}\int {q_Ïƒ(\tilde{x})}
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \frac{1}{q_Ïƒ(\tilde{x})}\frac{\partial q_Ïƒ(\tilde{x})}{\partial \tilde{x}} \Vert_2^2\Big] d\tilde{x}\\
&=\frac{1}{2}\int 
\Big[\Vert {q_Ïƒ(\tilde{x})}s_{\theta}( \tilde{x},\sigma ) - \frac{\partial q_Ïƒ(\tilde{x})}{\partial \tilde{x}} \Vert_2^2\Big] d\tilde{x}\\
&=\frac{1}{2}\int 
\Big[\Vert {q_Ïƒ(\tilde{x})}s_{\theta}( \tilde{x},\sigma ) - \frac{\partial \int q_Ïƒ(\tilde{x}|x) p_{data}(x) dx}{\partial \tilde{x}} \Vert_2^2\Big] d\tilde{x} \\
&=\frac{1}{2}\int 
\Big[\Vert {q_Ïƒ(\tilde{x})}s_{\theta}( \tilde{x},\sigma ) - \int \frac{\partial q_Ïƒ(\tilde{x}|x)}{\partial \tilde{x}} p_{data}(x) dx \Vert_2^2\Big] d\tilde{x} \\
&=\frac{1}{2}\int 
\Big[\Vert {\int q_Ïƒ(\tilde{x}|x) p_{data}(x) dx} \cdot s_{\theta}( \tilde{x},\sigma ) - \int q_Ïƒ(\tilde{x}|x) p_{data}(x)\frac{\partial \log q_Ïƒ(\tilde{x}|x)}{\partial \tilde{x}} dx \Vert_2^2\Big] d\tilde{x} \\
&=\frac{1}{2}\int_{\tilde{x}} \int_x q_Ïƒ(\tilde{x}|x) p_{data}(x) 
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \frac{\partial \log q_Ïƒ(\tilde{x}|x)}{\partial \tilde{x}}\Vert_2^2\Big] dx d\tilde{x} \\
&= \frac{1}{2}\mathbb{E}_{q_Ïƒ(\tilde{x}|x) p_{data}(x) }
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \nabla _{\tilde{x}} \log q_Ïƒ(\tilde{x}|x)\Vert_2^2\Big] \tag{2.20}
\end{align}
$$
***
æ³¨æ„ï¼šå®‹é£åšå£«åœ¨è®ºæ–‡ä¸blogæœ‰ä¸åŒçš„æ ‡è®°æ–¹æ³•ã€‚è®ºæ–‡æ›´å‡†ç¡®ç”¨çš„æ˜¯ $q_{\sigma}(x)$ ï¼Œä»£è¡¨ä¸ $p(x)$ ä¸åŒï¼›blogä¸Šç”¨çš„æ˜¯ $p_{\sigma}(x)$ ï¼Œä¸ºäº†ä»å…¬å¼ä¸Šç›´æ¥æ›¿æ¢ $p(x)$ ã€‚
***
è¿™é‡Œé¢è¿˜æœ‰ä¸€ä¸ªæ½œåœ¨æ¨ç†ã€‚å½“ $x$ æ˜¯ $D$ ç»´ï¼Œå³ ${x}\in \mathbb{R} ^D$ æ—¶ï¼Œç”±å¤šç»´é«˜æ–¯åˆ†å¸ƒ $f( \mathbf{x} ) = \frac{1}{(2\pi)^{\frac{D}{2}} | Î£ |^{\frac{1}{2}}} e^{- \frac{1}{2}( x - Î¼ )^T Î£^{-1}(x - Î¼)}$  å¯å¾—:
$$
\begin{align}
\nabla _{\tilde{x}} \log q_Ïƒ(\tilde{x}|x) &= \nabla _{\tilde{x}}(C - \frac{1}{2}(\tilde{x} - x )^T Î£^{-1}(\tilde{x} - x)) \\
&= -Î£^{-1}(\tilde{x} - x) \\
&= -\begin{bmatrix} ğœ_{1}^2 & & & \\ & ğœ_{2}^2 & & \\ & & \ddots &\\ & & &ğœ_{d}^2 \end{bmatrix} (\tilde{x} - x) \tag{2.21}\\
&= - \frac{\tilde{x} - x}{ğœ^2} \tag{2.22} \\
&= - \frac{\epsilon}{ğœ} \tag{2.23}
\end{align}
$$
å°†ï¼ˆ2.22ï¼‰å¸¦å…¥å…¬å¼ï¼ˆ2.20ï¼‰å¯ä»¥å†™ä¸ºå¦‚ä¸‹å½¢å¼ï¼š
$$
\begin{align}
& ~~~~ \frac{1}{2}\mathbb{E}_{q_Ïƒ(\tilde{x}|x) p_{data}(x) }
\Big[\Vert s_{\theta}( \tilde{x},\sigma ) - \nabla _{\tilde{x}} \log q_Ïƒ(\tilde{x}|x)\Vert_2^2\Big] \\
&= \frac{1}{2}\mathbb{E}_{q_Ïƒ(\tilde{x}|x)}\mathbb{E}_{p_{data}(x)}
\Big[\Big\Vert s_{\theta}( \tilde{x},\sigma ) + \frac{\tilde{x}-x}{Ïƒ^2}\Big\Vert_2^2\Big] \\ 
&= \frac{1}{2}\mathbb{E}_{p_{data}(x)}\mathbb{E}_{\tilde{x} \sim \mathcal{N}(\tilde{x}|x,Ïƒ^2I)}
\Big[\Big\Vert s_{\theta}( \tilde{x},\sigma ) + \frac{\tilde{x}-x}{Ïƒ^2}\Big\Vert_2^2\Big] \tag{2.24} \\
& =\mathcal{l}(\theta;\sigma) \tag{2.25}
\end{align}
$$
æˆ‘ä»¬æŠŠæœ€åå…¬å¼ï¼ˆ2.24ï¼‰çš„å†™æˆå…¬å¼ï¼ˆ2.25ï¼‰æ–¹ä¾¿åé¢ä½¿ç”¨ã€‚åœ¨å…¬å¼ï¼ˆ2.24ï¼‰ä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼Œä¸»è¦çš„é—®é¢˜åœ¨äºå™ªå£°åŠ›åº¦ $\sigma$ ã€‚å™ªå£°åŠ çš„å¤§ï¼ˆæç«¯æƒ…å†µå˜æˆçº¯å™ªå£°ï¼‰ä¼šå¯¼è‡´åŠ å™ªä¹‹åçš„æ•°æ®åˆ†å¸ƒä¸¥é‡åç¦»åŸå§‹æ•°æ®åˆ†å¸ƒï¼›åä¹‹ï¼Œå™ªå£°åŠ çš„å°ï¼ˆæç«¯æƒ…å†µå˜æˆ0å™ªå£°ï¼‰ä¸èƒ½å¾ˆå¥½çš„è§£å†³å‰è¿°å­˜åœ¨çš„é—®é¢˜ã€‚ä¸ºäº†æƒè¡¡è¿™ä¸¤ä¸ªæ–¹é¢ï¼Œä½œè€…æå‡ºåŒæ—¶ä½¿ç”¨å¤šä¸ªä¸åŒå¤§å°å™ªå£°çš„é€€ç«æ–¹æ¡ˆã€‚
### 2.2.6 é€€ç«æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·ï¼ˆannealed Langevin dynamicsï¼‰

æœ‰ $L$ ä¸ªé€’å¢çš„ $ğœ_1<ğœ_2<â‹¯<ğœ_L$ ï¼Œåˆ†å¸ƒ $q(X)$ ä¸æ¯ä¸ªé«˜æ–¯å™ªå£° $\sigma\epsilon \sim \mathcal{N}(0,ğœ_i^2I),i=1,2,â‹¯,L$ ç»“åˆæˆå—æ‰°åŠ¨çš„åˆ†å¸ƒã€‚

æˆ‘ä»¬å‘ç° $\sigma$ æœ€å¤Ÿå°æ—¶ï¼Œ $\tilde{x} \approx x$  ï¼Œã€‚

ï¼Œå…¶ä¸­å½“Â ${x}\in \mathbb{R} ^D$Â æ—¶Â $s_{\theta}\left( {x},\sigma \right) \in \mathbb{R} ^D$Â ã€‚ä¸€èˆ¬æŠŠÂ $s_{\theta}\left( {x};t \right)$Â ç§°ä¸ºå™ªå£°æ¡ä»¶åˆ†æ•°ç½‘ç»œã€‚


![](åˆ†æ•°åœ¨é«˜ä½åŒºåŸŸçš„ä½œç”¨.png)
æˆ‘ä»¬å†å›åˆ°å‘é‡åœºçš„å›¾ï¼Œè¿™ä¸ªå›¾ä»…ä»…æ¼”ç¤ºç”¨ã€‚çœŸå®æƒ…å†µæ˜¯å›¾åƒå¤§éƒ¨ä½æ˜¯çš„åŒºåŸŸæ˜¯ä½æ¦‚ç‡å¯†åº¦åŒºåŸŸï¼Œè€ŒæŸå¤±å‡½æ•°ç®€å•çš„äºŒé˜¶è®¡ç®—ä¼šå‡ºç°å¤§å¯†åº¦åŒºé—´â€œå¦¨ç¢â€å°å¯†åº¦åŒºé—´çš„é—®é¢˜ã€‚è¿™ç§æƒ…å†µæˆ‘ä»¬ä¼šåŠ å¤§å™ªå£°ï¼Œå¡«å……æ•´ä¸ªåŒºåŸŸã€‚è¾ƒå¤§çš„å™ªå£°æ˜¾ç„¶å¯ä»¥è¦†ç›–ä½å¯†åº¦åŒºåŸŸï¼Œåœ¨æ›´å¤šåŒºåŸŸè·å¾—æ›´å¥½çš„è¯„åˆ†ä¼°è®¡ï¼Œä½†æ˜¯è¿‡åº¦ç ´åäº†æ•°æ®ã€‚å¦‚å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¾¹ç•Œæ¨¡ç³Šï¼Œè¿™å°±æ˜¯å¼ºåº¦è¿‡å¤§çš„å™ªå£°åä¹‹ä¼šå¹²æ‰°åˆ°åŸå§‹æ•°æ®çš„åˆ†å¸ƒçš„è¡¨ç°ã€‚è¿™ç§æƒ…å†µè¿˜ä¼šé€ æˆä¼°è®¡åˆ†æ•°çš„è¯¯å·®å¢å¤§ï¼Œä»è€ŒåŸºäºåŠ å™ªåçš„åˆ†æ•°ä½¿ç”¨æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦é‡‡æ ·ç”Ÿæˆçš„ç»“æœä¹Ÿå°±ä¸å¤ªç¬¦åˆåŸæ•°æ®åˆ†å¸ƒã€‚ç›¸ååœ°ï¼Œå™ªå£°å¼ºåº¦å°èƒ½å¤Ÿè·å¾—ä¸åŸæ•°æ®åˆ†å¸ƒè¾ƒä¸ºè¿‘ä¼¼çš„æ•ˆæœï¼Œä½†æ˜¯å´ä¸èƒ½å¤Ÿå¾ˆå¥½åœ°â€œå¡«å……â€ä½æ¦‚ç‡å¯†åº¦åŒºåŸŸã€‚ä¸ºäº†è¾¾åˆ°ä¸¤è€…æœ€ä½³ã€‚æˆ‘ä»¬ä½¿ç”¨äº†å¤šå°ºåº¦å™ªå£°æ‰°åŠ¨ã€‚






[1] Jonathan Ho, Ajay Jain, Pieter Abbeel. Denoising Diffusion Probabilistic Models. arXiv preprint  arXiv:2006.11239v2.
[2] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. arXiv:2011.13456
[3] Yang Song, and Stefano Ermon. Generative Modeling by Estimating Gradients of the Data Distribution. arXiv:1907.05600
[4] Pascal Vincent. A Connection Between Score Matching and Denoising Autoencoders